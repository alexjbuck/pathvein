{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Pathvein","text":"<p> Rich and deep file structure pattern matching </p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>Pathvein is a high-performance Python library for pattern matching against file system structures. It combines the expressiveness of Python with the speed of Rust to provide a powerful tool for:</p> <ul> <li>Scanning directories for complex structural patterns</li> <li>Validating file organization against requirements</li> <li>Copying matched structures to organized destinations</li> <li>Assessing which patterns individual files belong to</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Rich Pattern Matching: Define complex file structure requirements with required and optional components</li> <li>Rust-Powered Performance: 5-10x faster directory walking and 3-5x faster pattern matching</li> <li>Cloud Storage Support: Works with S3 and other cloud storage via fsspec</li> <li>Python Fallback: Automatically falls back to pure Python if Rust unavailable</li> <li>Type Safe: Full type annotations with runtime validation using Pydantic</li> <li>CLI &amp; Library: Use programmatically or from the command line</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from pathlib import Path\nfrom pathvein import scan, shuffle_to, FileStructurePattern\n\n# Define a pattern for an experiment directory\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"config.yaml\", \"results.csv\"],\n    optional_files=[\"notes.txt\"]\n)\n\n# Find all matching directories\nmatches = scan(\n    source=Path(\"data\"),\n    patterns=[pattern]\n)\n\n# Copy matches to organized destination\nshuffle_to(\n    matches=matches,\n    destination=Path(\"organized_data\")\n)\n</code></pre>"},{"location":"#performance","title":"Performance","text":"<p>Pathvein includes a Rust backend that provides significant performance improvements:</p> <ul> <li>5-10x faster directory walking with parallel traversal</li> <li>3-5x faster pattern matching with compiled globs</li> <li>100x+ faster for network filesystems via caching</li> </ul> <p>The Rust backend is built automatically when installed from source with cargo available, or included in PyPI wheels.</p>"},{"location":"#get-started","title":"Get Started","text":"<p>Ready to dive in? Check out the installation guide and quick start tutorial.</p> <p>For detailed API documentation, see the API Reference.</p>"},{"location":"about/architecture/","title":"Architecture","text":"<p>Pathvein is a hybrid Python/Rust library that combines the expressiveness of Python with the performance of Rust.</p>"},{"location":"about/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>User Code (Python)\n    \u2193\nscan(path, patterns)\n    \u2193\nPath Type Detection (Python)\n    \u2193\n    \u251c\u2500\u2500\u2500 Local Filesystem \u2500\u2500\u2500\u2192 Rust Backend (walk_parallel)\n    \u2502                              \u2193\n    \u2502                          Directory Walking (5-10x faster)\n    \u2502                              \u2193\n    \u2514\u2500\u2500\u2500 Cloud Storage \u2500\u2500\u2500\u2500\u2500\u2500\u2192 Python Backend (fsspec/UPath)\n                                   \u2193\n                               Network I/O (S3/GCS/Azure)\n\n    Both paths converge:\n        \u2193\n    Pattern Matching (Rust PatternMatcher)\n        \u2193\n    Results (Python Set[ScanResult])\n</code></pre>"},{"location":"about/architecture/#components","title":"Components","text":""},{"location":"about/architecture/#python-layer","title":"Python Layer","text":"<p>Located in <code>src/pathvein/</code>:</p> <ul> <li>lib.py: Core functions (<code>scan</code>, <code>shuffle</code>, <code>assess</code>)</li> <li>pattern.py: <code>FileStructurePattern</code> class and matching logic</li> <li>_path_utils.py: Python fallback for path operations</li> <li>_backend.py: Backend detection and Rust bindings</li> <li>cli.py: Command-line interface (optional)</li> </ul>"},{"location":"about/architecture/#rust-layer","title":"Rust Layer","text":"<p>Located in <code>src/</code>:</p> <ul> <li>lib.rs: PyO3 module definition</li> <li>walk.rs: <code>walk_parallel()</code> - Parallel directory walking</li> <li>pattern.rs: <code>PatternMatcher</code> - Fast glob pattern matching</li> </ul>"},{"location":"about/architecture/#execution-flow","title":"Execution Flow","text":""},{"location":"about/architecture/#local-filesystem-scan","title":"Local Filesystem Scan","text":"Step Component Language Description 1 scan() Python Entry point, receives path and patterns 2 Type detection Python Check if <code>type(source) is Path</code> 3 walk_parallel() Rust Parallel directory traversal using walkdir + rayon 4 Return entries Python Receive list of (path, dirs, files) tuples 5 PatternMatcher Rust Compile patterns into optimized DFA using globset 6 Pattern matching Rust Fast pattern matching for each filename 7 Collect results Python Build Set[ScanResult] <p>Performance: ~5-10x faster than pure Python</p> <p>Bottleneck: Directory walking (I/O bound, Rust parallelism helps)</p>"},{"location":"about/architecture/#cloud-storage-scan","title":"Cloud Storage Scan","text":"Step Component Language Description 1 scan() Python Entry point, receives path and patterns 2 Type detection Python Check if path is UPath/S3Path 3 walk_python() Python Use fsspec for S3/GCS/Azure APIs 4 Return entries Python List of (path, dirs, files) tuples 5 PatternMatcher Rust Compile patterns into optimized DFA 6 Pattern matching Rust Fast pattern matching for each filename 7 Collect results Python Build Set[ScanResult] <p>Performance: ~3-5x faster pattern matching vs Python fnmatch</p> <p>Bottleneck: Network I/O (95% of time), Rust pattern matching helps with remaining 5%</p>"},{"location":"about/architecture/#ffi-boundary","title":"FFI Boundary","text":"<p>The Python-Rust boundary is crossed at specific points:</p>"},{"location":"about/architecture/#1-walk_parallel","title":"1. walk_parallel()","text":"<pre><code># Python\nfor dirpath, dirnames, filenames in walk_parallel(str(source)):\n    # Process entries\n</code></pre> <pre><code>// Rust\n#[pyfunction]\npub fn walk_parallel(path: String) -&gt; PyResult&lt;Vec&lt;DirEntry&gt;&gt; {\n    // walkdir + rayon for parallel traversal\n}\n</code></pre> <p>FFI Cost: Single call per scan (amortized)</p>"},{"location":"about/architecture/#2-patternmatcher","title":"2. PatternMatcher","text":"<pre><code># Python\nmatcher = PatternMatcher([\"*.py\", \"test_*.rs\"])\nif matcher.matches(\"file.py\"):\n    print(\"Matched!\")\n</code></pre> <pre><code>// Rust\n#[pyclass]\npub struct PatternMatcher {\n    globset: GlobSet,  // Compiled patterns\n}\n</code></pre> <p>FFI Cost: One per pattern set (cached in Rust)</p>"},{"location":"about/architecture/#3-pattern-matching","title":"3. Pattern Matching","text":"<pre><code># Python - many calls per scan\nfor filename in filenames:\n    if matcher.matches(filename):  # FFI call\n        # Handle match\n</code></pre> <pre><code>// Rust - optimized hot path\npub fn matches(&amp;self, path: &amp;str) -&gt; bool {\n    self.globset.is_match(path)  // DFA matching\n}\n</code></pre> <p>FFI Cost: One per file, but extremely fast (microseconds)</p>"},{"location":"about/architecture/#performance-impact","title":"Performance Impact","text":""},{"location":"about/architecture/#local-filesystem","title":"Local Filesystem","text":"<pre><code>Directory Walking: 60% of time\n\u251c\u2500 Python os.walk: ~50ms\n\u2514\u2500 Rust walk_parallel: ~30ms  [1.6x faster \u2713]\n\nPattern Matching: 40% of time\n\u251c\u2500 Python fnmatch: ~20ms\n\u2514\u2500 Rust PatternMatcher: ~5ms  [4x faster \u2713]\n\nTotal: ~1.5-2x faster end-to-end\n</code></pre>"},{"location":"about/architecture/#cloud-storage-s3","title":"Cloud Storage (S3)","text":"<pre><code>Network I/O: 95% of time (~2000ms)\n\u2514\u2500 Python fsspec: Only option [Rust wouldn't help]\n\nPattern Matching: 5% of time\n\u251c\u2500 Python fnmatch: ~20ms\n\u2514\u2500 Rust PatternMatcher: ~5ms  [4x faster \u2713]\n\nTotal: ~1.05x faster (network dominates)\n</code></pre>"},{"location":"about/architecture/#design-decisions","title":"Design Decisions","text":""},{"location":"about/architecture/#why-hybrid","title":"Why Hybrid?","text":"<p>Rust Strengths: - CPU-intensive operations (pattern matching, parallel traversal) - Memory efficiency (SmallVec, zero-copy) - Fearless concurrency (rayon)</p> <p>Python Strengths: - High-level orchestration - Rich ecosystem (fsspec, UPath, boto3) - Easy user API</p>"},{"location":"about/architecture/#why-automatic-backend-selection","title":"Why Automatic Backend Selection?","text":"<pre><code># Seamless fallback\nmatches = scan(Path(\"/local/data\"), [pattern])  # Uses Rust\nmatches = scan(UPath(\"s3://bucket\"), [pattern])  # Uses Python\n</code></pre> <p>Users don't need to know or care which backend is used.</p>"},{"location":"about/architecture/#why-pyo3","title":"Why PyO3?","text":"<ul> <li>Zero-cost abstractions</li> <li>Memory safety guarantees</li> <li>Native Python types</li> <li>Excellent documentation</li> <li>Automatic docstring exposure: Rust doc comments \u2192 Python <code>__doc__</code></li> </ul>"},{"location":"about/architecture/#caching-strategy","title":"Caching Strategy","text":"<p>Pathvein uses multiple caching layers:</p>"},{"location":"about/architecture/#1-directory-listing-cache","title":"1. Directory Listing Cache","text":"<pre><code># _path_utils.py\n@lru_cache(maxsize=None)\ndef iterdir(path: Path) -&gt; Tuple[Path, List[str], List[str]]:\n    # Cache directory contents\n</code></pre> <p>Benefit: 100x+ faster for network filesystems</p> <p>Trade-off: Memory usage for cached listings</p>"},{"location":"about/architecture/#2-pattern-compilation-cache","title":"2. Pattern Compilation Cache","text":"<pre><code>// pattern.rs\nstatic PATTERN_CACHE: Mutex&lt;Option&lt;LruCache&lt;String, GlobMatcher&gt;&gt;&gt; = ...;\n</code></pre> <p>Benefit: Avoid recompiling patterns (maxsize=256)</p> <p>Trade-off: 256 patterns \u00d7 ~1KB each = ~256KB</p>"},{"location":"about/architecture/#3-patternmatcher-object","title":"3. PatternMatcher Object","text":"<pre><code># pattern.py - reuse matcher across files\nmatcher = PatternMatcher(self.all_files)\nfor file in files:\n    if matcher.matches(file):  # No recompilation\n</code></pre> <p>Benefit: Compile once, match many times</p> <p>Trade-off: None (pure optimization)</p>"},{"location":"about/architecture/#module-organization","title":"Module Organization","text":"<pre><code>pathvein/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 pathvein/           # Python package\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py     # Public API exports\n\u2502   \u2502   \u251c\u2500\u2500 lib.py          # Core functions\n\u2502   \u2502   \u251c\u2500\u2500 pattern.py      # Pattern class\n\u2502   \u2502   \u251c\u2500\u2500 _backend.py     # Rust bindings\n\u2502   \u2502   \u251c\u2500\u2500 _path_utils.py  # Python fallback\n\u2502   \u2502   \u2514\u2500\u2500 cli.py          # CLI (optional)\n\u2502   \u251c\u2500\u2500 lib.rs              # Rust module root\n\u2502   \u251c\u2500\u2500 walk.rs             # Parallel walking\n\u2502   \u2514\u2500\u2500 pattern.rs          # Pattern matching\n\u251c\u2500\u2500 Cargo.toml              # Rust dependencies\n\u251c\u2500\u2500 pyproject.toml          # Python package config\n\u2514\u2500\u2500 docs/                   # Documentation\n</code></pre>"},{"location":"about/architecture/#build-process","title":"Build Process","text":""},{"location":"about/architecture/#maturin","title":"maturin","text":"<p>Pathvein uses maturin for building:</p> <pre><code>[build-system]\nrequires = [\"maturin&gt;=1.0,&lt;2.0\"]\nbuild-backend = \"maturin\"\n\n[tool.maturin]\nfeatures = [\"pyo3/extension-module\"]\nmodule-name = \"pathvein._pathvein_rs\"\npython-source = \"src\"\n</code></pre> <p>Build flow: 1. maturin detects Rust code 2. Compiles Rust \u2192 <code>_pathvein_rs.so</code> (or <code>.pyd</code> on Windows) 3. Copies Python code to package 4. Creates wheel with both</p> <p>Fallback: If Rust unavailable, Python-only mode works</p>"},{"location":"about/architecture/#testing-strategy","title":"Testing Strategy","text":""},{"location":"about/architecture/#python-tests","title":"Python Tests","text":"<pre><code># tests/test_lib.py\ndef test_scan_local():\n    matches = scan(Path(\"data\"), [pattern])\n    assert len(matches) &gt; 0\n</code></pre>"},{"location":"about/architecture/#property-based-tests","title":"Property-Based Tests","text":"<pre><code># tests/strategies.py - using hypothesis\n@given(path_strategy(), pattern_strategy())\ndef test_scan_properties(path, pattern):\n    matches = scan(path, [pattern])\n    # Check invariants\n</code></pre>"},{"location":"about/architecture/#backend-tests","title":"Backend Tests","text":"<pre><code>def test_rust_backend():\n    assert get_backend_info() == \"rust\"\n\ndef test_walk_parallel():\n    results = list(walk_parallel(\"/tmp\"))\n    assert len(results) &gt; 0\n</code></pre>"},{"location":"about/architecture/#future-optimizations","title":"Future Optimizations","text":"<p>Potential areas for improvement:</p> <ol> <li>Parallel Pattern Matching: Use rayon to match patterns across files in parallel</li> <li>Async I/O: Add async variants for cloud storage operations</li> <li>Memory Mapping: Use mmap for very large directory structures</li> <li>SIMD: Leverage SIMD instructions for string matching</li> <li>Custom Allocator: Use jemalloc or mimalloc for better performance</li> </ol>"},{"location":"about/architecture/#summary","title":"Summary","text":"<p>What Rust Does: - \u2705 Local directory walking (<code>walk_parallel</code>) - \u2705 Pattern compilation (<code>PatternMatcher</code>) - \u2705 Pattern matching (<code>matcher.matches</code>)</p> <p>What Python Does: - \u2705 Cloud storage walking (fsspec/UPath) - \u2705 Control flow and orchestration - \u2705 Path type detection - \u2705 Result collection</p> <p>Key Insight: Rust handles CPU-intensive operations, Python handles I/O and orchestration. The FFI boundary is crossed strategically to minimize overhead while maximizing performance gains.</p>"},{"location":"about/changelog/","title":"Changelog","text":"<p>All notable changes to pathvein are documented in this file.</p>"},{"location":"about/changelog/#090","title":"0.9.0","text":""},{"location":"about/changelog/#minor-changes","title":"Minor Changes","text":"<ul> <li>#43 Add a method to find the possible mission root directories of a pattern-file set</li> <li>#43 Added threaded copy operations to concurrently process files</li> </ul>"},{"location":"about/changelog/#patch-changes","title":"Patch Changes","text":"<ul> <li>#34 Changed private path utils to public</li> </ul>"},{"location":"about/changelog/#080","title":"0.8.0","text":""},{"location":"about/changelog/#minor-changes_1","title":"Minor Changes","text":"<ul> <li>#31 Added caching to the path walk functionality</li> </ul> <p>Specifically cached the results of <code>_iterdir</code> which powers the core of the path <code>walk</code> function.</p>"},{"location":"about/changelog/#071","title":"0.7.1","text":""},{"location":"about/changelog/#patch-changes_1","title":"Patch Changes","text":"<ul> <li>#24 Added support for static type checking with <code>py.typed</code></li> </ul>"},{"location":"about/changelog/#070","title":"0.7.0","text":""},{"location":"about/changelog/#minor-changes_2","title":"Minor Changes","text":"<ul> <li>#21 Implemented and tested s3 path support</li> </ul>"},{"location":"about/changelog/#062","title":"0.6.2","text":""},{"location":"about/changelog/#patch-changes_2","title":"Patch Changes","text":"<ul> <li>#15 Fix CI to remove use of make</li> </ul>"},{"location":"about/changelog/#061","title":"0.6.1","text":""},{"location":"about/changelog/#patch-changes_3","title":"Patch Changes","text":"<ul> <li>Fix configuration for creating GitHub releases from changesets</li> <li>Update README to reflect breaking changes to the API</li> <li>Bump cross-spawn version to 7.0.6 to resolve security audit</li> </ul>"},{"location":"about/changelog/#060","title":"0.6.0","text":""},{"location":"about/changelog/#minor-changes_3","title":"Minor Changes","text":"<ul> <li>BREAKING CHANGE: Change the library scan and shuffle API</li> </ul> <p>The library scan and shuffle functions have been made orthogonal and to accept in-memory objects   instead of taking file paths.</p> <p>Added <code>shuffle_to</code> and <code>shuffle_with</code> to allow shuffling to a fixed destination or shuffling to   a destination defined by some function for each match result from <code>scan</code>.</p> <ul> <li>Add initial prop-testing suite. Coverage improving</li> </ul>"},{"location":"about/changelog/#patch-changes_4","title":"Patch Changes","text":"<ul> <li>Fix bug preventing pattern matching to occur during scan</li> <li>Remove shutil copy and pathlib.Path.walk or os.walk</li> </ul>"},{"location":"about/changelog/#056","title":"0.5.6","text":""},{"location":"about/changelog/#patch-changes_5","title":"Patch Changes","text":"<ul> <li>Update README</li> </ul>"},{"location":"about/changelog/#055","title":"0.5.5","text":""},{"location":"about/changelog/#patch-changes_6","title":"Patch Changes","text":"<ul> <li>Resize logo in readme</li> </ul>"},{"location":"about/changelog/#054","title":"0.5.4","text":""},{"location":"about/changelog/#patch-changes_7","title":"Patch Changes","text":"<ul> <li>Fix type annotation error in typer cli arguments</li> <li>Fix logging</li> <li>Update ci and add yarn ecosystem to use changesets</li> <li>Update README</li> </ul>"},{"location":"about/changelog/#052","title":"0.5.2","text":""},{"location":"about/changelog/#patch-changes_8","title":"Patch Changes","text":"<ul> <li>Update ci and add yarn ecosystem to use changesets</li> <li>Fix uv lockfile</li> </ul>"},{"location":"about/changelog/#051","title":"0.5.1","text":""},{"location":"about/changelog/#fix","title":"Fix","text":"<ul> <li>Change runs-on setting for build and check workflow</li> </ul>"},{"location":"about/changelog/#050","title":"0.5.0","text":""},{"location":"about/changelog/#features","title":"Features","text":"<ul> <li>Restructure pathvein library and extract cli into separate optional module</li> </ul>"},{"location":"about/changelog/#fix_1","title":"Fix","text":"<ul> <li>Update uv lockfile</li> </ul>"},{"location":"about/changelog/#040","title":"0.4.0","text":""},{"location":"about/changelog/#features_1","title":"Features","text":"<ul> <li>Add CI pipeline to create GitLab releases on new tags</li> </ul>"},{"location":"about/changelog/#fix_2","title":"Fix","text":"<ul> <li>Add updated uv.lock file</li> </ul>"},{"location":"about/changelog/#030","title":"0.3.0","text":""},{"location":"about/changelog/#breaking-change","title":"BREAKING CHANGE","text":"<ul> <li>Entry point is now called <code>org</code>, which is also <code>organizer.cli</code></li> </ul>"},{"location":"about/changelog/#features_2","title":"Features","text":"<ul> <li>Refactor into package and update pyproject to support building wheel and sdist</li> </ul>"},{"location":"about/changelog/#020","title":"0.2.0","text":""},{"location":"about/changelog/#features_3","title":"Features","text":"<ul> <li>Add commitizen as a dev dependency</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the Pathvein API reference documentation.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>Pathvein's API is organized into several modules:</p> <ul> <li>Core Functions: Main functions like <code>scan()</code>, <code>shuffle()</code>, <code>assess()</code></li> <li>FileStructurePattern: Pattern definition and matching</li> <li>Data Types: Named tuples like <code>ScanResult</code>, <code>ShuffleInput</code>, <code>ShuffleResult</code></li> <li>Backend: Backend information and utilities</li> </ul>"},{"location":"api/#quick-reference","title":"Quick Reference","text":""},{"location":"api/#scanning","title":"Scanning","text":"<pre><code>from pathvein import scan, assess\n\n# Scan directory for patterns\nmatches = scan(source, patterns)\n\n# Assess which pattern a file belongs to\nresults = assess(file, patterns)\n</code></pre>"},{"location":"api/#shuffling","title":"Shuffling","text":"<pre><code>from pathvein import shuffle, shuffle_to, shuffle_with\n\n# Copy to single destination\nshuffle_to(matches, destination)\n\n# Copy with custom logic\nshuffle_with(matches, destination_fn)\n\n# Full control\nshuffle(shuffle_def)\n</code></pre>"},{"location":"api/#patterns","title":"Patterns","text":"<pre><code>from pathvein import FileStructurePattern\n\n# Create pattern\npattern = FileStructurePattern(\n    directory_name=\"*\",\n    files=[\"*.csv\"],\n    directories=[nested_pattern]\n)\n\n# Load from JSON\npattern = FileStructurePattern.load_json(path)\n\n# Check match\nif pattern.matches((dirpath, dirnames, filenames)):\n    print(\"Matched!\")\n</code></pre>"},{"location":"api/#type-annotations","title":"Type Annotations","text":"<p>Pathvein is fully type-annotated. Use with mypy or other type checkers:</p> <pre><code>from pathlib import Path\nfrom typing import Set\nfrom pathvein import scan, FileStructurePattern, ScanResult\n\ndef find_matches(root: Path, pattern: FileStructurePattern) -&gt; Set[ScanResult]:\n    return scan(root, [pattern])\n</code></pre>"},{"location":"api/#import-reference","title":"Import Reference","text":"<p>All public APIs are exported from the top-level package:</p> <pre><code>from pathvein import (\n    # Functions\n    scan,\n    assess,\n    shuffle,\n    shuffle_to,\n    shuffle_with,\n    get_backend_info,\n\n    # Classes\n    FileStructurePattern,\n\n    # Types\n    ScanResult,\n    ShuffleInput,\n    ShuffleResult,\n)\n</code></pre>"},{"location":"api/backend/","title":"Backend Information","text":"<p>Pathvein includes both a high-performance Rust backend and a pure Python fallback.</p>"},{"location":"api/backend/#get_backend_info","title":"get_backend_info","text":"<p>Returns information about which backend is currently active.</p>"},{"location":"api/backend/#pathvein._backend.get_backend_info","title":"pathvein._backend.get_backend_info","text":"<pre><code>get_backend_info() -&gt; dict\n</code></pre> <p>Get information about the current backend.</p> RETURNS DESCRIPTION <code>dict</code> <p>Dictionary with backend information:</p> <code>dict</code> <ul> <li>has_rust: Whether Rust backend is available</li> </ul> <code>dict</code> <ul> <li>backend: \"rust\" or \"python\"</li> </ul> <code>dict</code> <ul> <li>features: List of available features</li> </ul> Source code in <code>src/pathvein/_backend.py</code> <pre><code>def get_backend_info() -&gt; dict:\n    \"\"\"\n    Get information about the current backend.\n\n    Returns:\n        Dictionary with backend information:\n        - has_rust: Whether Rust backend is available\n        - backend: \"rust\" or \"python\"\n        - features: List of available features\n    \"\"\"\n    return {\n        \"has_rust\": HAS_RUST_BACKEND,\n        \"backend\": \"rust\" if HAS_RUST_BACKEND else \"python\",\n        \"features\": [\n            \"parallel_walk\" if HAS_RUST_BACKEND else None,\n            \"fast_pattern_matching\" if HAS_RUST_BACKEND else None,\n        ],\n    }\n</code></pre>"},{"location":"api/backend/#usage","title":"Usage","text":"<pre><code>from pathvein import get_backend_info\n\nbackend = get_backend_info()\nprint(f\"Active backend: {backend}\")\n</code></pre>"},{"location":"api/backend/#return-values","title":"Return Values","text":"<ul> <li><code>\"rust\"</code> - Rust backend is active (best performance)</li> <li><code>\"python\"</code> - Pure Python fallback is active</li> </ul>"},{"location":"api/backend/#rust-backend","title":"Rust Backend","text":"<p>When available, the Rust backend provides:</p> <ul> <li>5-10x faster directory traversal with <code>walk_parallel()</code></li> <li>3-5x faster pattern matching with compiled glob patterns</li> <li>Parallel processing across CPU cores</li> <li>Optimized memory usage with SmallVec</li> </ul>"},{"location":"api/backend/#functions","title":"Functions","text":"<p>The Rust backend exposes these functions (automatically used by pathvein):</p>"},{"location":"api/backend/#walk_parallel","title":"walk_parallel","text":"<pre><code>from pathvein._backend import walk_parallel\n\n# Parallel directory walking (Rust implementation)\nfor dirpath, dirnames, filenames in walk_parallel(\"/path/to/scan\"):\n    print(f\"{dirpath}: {len(filenames)} files\")\n</code></pre> <p>Parameters: - <code>path: str</code> - Root directory to walk - <code>max_depth: Optional[int]</code> - Maximum depth (None = unlimited) - <code>follow_links: bool</code> - Whether to follow symbolic links (default: False)</p> <p>Returns: - <code>List[Tuple[str, List[str], List[str]]]</code> - List of (path, dirnames, filenames)</p>"},{"location":"api/backend/#patternmatcher","title":"PatternMatcher","text":"<pre><code>from pathvein._backend import PatternMatcher\n\n# Compile patterns once for efficient matching\nmatcher = PatternMatcher([\"*.py\", \"test_*.rs\"])\n\n# Check single match\nif matcher.matches(\"test_file.py\"):\n    print(\"Matched!\")\n\n# Get all matching patterns\npatterns = matcher.matching_patterns(\"test_file.py\")\nprint(f\"Matched patterns: {patterns}\")\n\n# Check if matches all patterns\nif matcher.matches_all(\"test_file.py.rs\"):\n    print(\"Matches all patterns!\")\n</code></pre> <p>Methods: - <code>__init__(patterns: List[str])</code> - Create matcher from glob patterns - <code>matches(path: str) -&gt; bool</code> - Check if path matches any pattern - <code>matching_patterns(path: str) -&gt; List[str]</code> - Get all matching patterns - <code>matches_all(path: str) -&gt; bool</code> - Check if path matches all patterns</p>"},{"location":"api/backend/#match_pattern","title":"match_pattern","text":"<pre><code>from pathvein._backend import match_pattern\n\n# Single pattern matching (cached)\nif match_pattern(\"file.py\", \"*.py\"):\n    print(\"Matched!\")\n</code></pre> <p>Parameters: - <code>path: str</code> - File or directory name to match - <code>pattern: str</code> - Glob pattern</p> <p>Returns: - <code>bool</code> - True if matches, False otherwise</p> <p>Note: Uses LRU cache (maxsize=256) for compiled patterns. For multiple matches, use <code>PatternMatcher</code> instead.</p>"},{"location":"api/backend/#python-backend","title":"Python Backend","text":"<p>The pure Python backend is used when:</p> <ul> <li>Rust extension is not available</li> <li>Working with cloud storage (S3, GCS, etc.)</li> <li>Using path-like objects other than <code>pathlib.Path</code></li> </ul>"},{"location":"api/backend/#functions_1","title":"Functions","text":"<p>The Python backend provides equivalent functionality:</p> <pre><code>from pathvein._path_utils import walk\n\n# Python directory walking\nfor dirpath, dirnames, filenames in walk(Path(\"/path/to/scan\")):\n    print(f\"{dirpath}: {len(filenames)} files\")\n</code></pre>"},{"location":"api/backend/#automatic-backend-selection","title":"Automatic Backend Selection","text":"<p>Pathvein automatically selects the appropriate backend:</p> <pre><code>from pathlib import Path\nfrom upath import UPath\nfrom pathvein import scan\n\n# Uses Rust backend for local paths\nlocal_matches = scan(Path(\"/local/data\"), [pattern])\n\n# Automatically uses Python backend for S3\ns3_matches = scan(UPath(\"s3://bucket/data\"), [pattern])\n</code></pre>"},{"location":"api/backend/#detection-logic","title":"Detection Logic","text":"<pre><code>from pathlib import Path\n\n# In scan() function\nif type(source) is Path:\n    # Use Rust backend (fast)\n    walk_parallel(str(source))\nelse:\n    # Use Python backend (compatible)\n    walk_python(source)\n</code></pre>"},{"location":"api/backend/#performance-comparison","title":"Performance Comparison","text":"Operation Python Rust Speedup Directory Walking 1x 5-10x 5-10x faster Pattern Matching 1x 3-5x 3-5x faster Pattern Compilation 1x 10x+ 10x+ faster"},{"location":"api/backend/#benchmarks","title":"Benchmarks","text":"<pre><code>import time\nfrom pathlib import Path\nfrom pathvein import scan, get_backend_info, FileStructurePattern\n\npattern = FileStructurePattern(files=[\"*.py\"])\n\nprint(f\"Backend: {get_backend_info()}\")\n\nstart = time.time()\nmatches = scan(Path(\"/large/directory\"), [pattern])\nelapsed = time.time() - start\n\nprint(f\"Found {len(matches)} matches in {elapsed:.2f}s\")\n</code></pre>"},{"location":"api/backend/#building-with-rust","title":"Building with Rust","text":"<p>To build pathvein with the Rust backend:</p>"},{"location":"api/backend/#requirements","title":"Requirements","text":"<ul> <li>Rust 1.70 or newer</li> <li>cargo (comes with Rust)</li> </ul>"},{"location":"api/backend/#install-rust","title":"Install Rust","text":"<pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre>"},{"location":"api/backend/#build-from-source","title":"Build from Source","text":"<pre><code>git clone https://github.com/alexjbuck/pathvein.git\ncd pathvein\npip install .\n</code></pre> <p>Maturin will automatically detect Rust and build the extension.</p>"},{"location":"api/backend/#verify-rust-backend","title":"Verify Rust Backend","text":"<pre><code>from pathvein import get_backend_info\n\nassert get_backend_info() == \"rust\", \"Rust backend not available\"\nprint(\"\u2713 Rust backend is active\")\n</code></pre>"},{"location":"api/backend/#fallback-behavior","title":"Fallback Behavior","text":"<p>If the Rust backend is unavailable, pathvein falls back gracefully:</p> <pre><code># This works regardless of backend\nfrom pathvein import scan\n\nmatches = scan(source, [pattern])\n# Uses Rust if available, Python otherwise\n</code></pre> <p>No code changes needed - the API is identical.</p>"},{"location":"api/backend/#cloud-storage","title":"Cloud Storage","text":"<p>For cloud storage, install the S3 extra:</p> <pre><code>pip install 'pathvein[s3]'\n</code></pre> <p>Then use with UPath:</p> <pre><code>from upath import UPath\nfrom pathvein import scan, FileStructurePattern\n\npattern = FileStructurePattern(files=[\"*.parquet\"])\n\n# Automatically uses Python backend for S3\nmatches = scan(\n    source=UPath(\"s3://my-bucket/data/\"),\n    patterns=[pattern]\n)\n</code></pre> <p>The Python backend works with any fsspec-compatible filesystem: - S3 (<code>s3://</code>) - Google Cloud Storage (<code>gs://</code>) - Azure Blob Storage (<code>az://</code>) - HTTP/HTTPS - And more</p>"},{"location":"api/functions/","title":"Core Functions","text":"<p>This page documents the main functions in pathvein.</p>"},{"location":"api/functions/#scan","title":"scan","text":""},{"location":"api/functions/#pathvein.lib.scan","title":"pathvein.lib.scan","text":"<pre><code>scan(source: Path, patterns: Iterable[FileStructurePattern]) -&gt; Set[ScanResult]\n</code></pre> <p>Recursively scan a directory path for directory structures that match the requirements</p> Source code in <code>src/pathvein/lib.py</code> <pre><code>def scan(\n    source: Path,\n    patterns: Iterable[FileStructurePattern],\n) -&gt; Set[ScanResult]:\n    \"\"\"Recursively scan a directory path for directory structures that match the requirements\"\"\"\n\n    logger.info(\"Beginning scan of %s\", source.as_posix())\n\n    # Resolve to real paths to ensure that things like .exist() and .is_dir() work correctly\n    source = source.resolve()\n\n    # Consume the iterable into a list so we can reuse it\n    pattern_list = list(patterns)\n\n    for pattern in pattern_list:\n        logger.debug(\"Scanning for paths that match structure: %s\", pattern)\n\n    matches = set()\n\n    # Use Rust-backed walk_parallel ONLY for standard Path objects (local filesystem)\n    # For cloud storage (UPath, S3Path, etc.), use Python walk() which supports any path-like object\n    if type(source) is Path:\n        # Local filesystem - use Rust for performance\n        for dirpath_str, dirnames, filenames in walk_parallel(str(source)):\n            dirpath = Path(dirpath_str)\n            logger.debug(\"Walk: (%s, %s, %s)\", dirpath, dirnames, filenames)\n            for pattern in pattern_list:\n                if pattern.matches((dirpath, dirnames, filenames)):\n                    logger.debug(\"Matched structure %s in %s\", pattern, dirpath)\n                    matches.add(ScanResult(dirpath, pattern))\n    else:\n        # Cloud storage or other path-like objects - use Python walk()\n        logger.debug(\"Using Python walk for non-local path: %s\", type(source))\n        for dirpath, dirnames, filenames in walk_python(source):\n            logger.debug(\"Walk: (%s, %s, %s)\", dirpath, dirnames, filenames)\n            for pattern in pattern_list:\n                if pattern.matches((dirpath, dirnames, filenames)):\n                    logger.debug(\"Matched structure %s in %s\", pattern, dirpath)\n                    matches.add(ScanResult(dirpath, pattern))\n\n    logger.debug(\"Matching paths: %s\", matches)\n\n    return matches\n</code></pre>"},{"location":"api/functions/#assess","title":"assess","text":""},{"location":"api/functions/#pathvein.lib.assess","title":"pathvein.lib.assess","text":"<pre><code>assess(file: Path, patterns: Iterable[FileStructurePattern]) -&gt; Generator[ScanResult, None, None]\n</code></pre> <p>Assess which patterns a file belongs to and find the pattern root directories.</p> <p>Given a file path, this function determines which patterns it could belong to by working backwards from the file to find candidate root directories, then validating that those roots actually match the pattern.</p> <p>This is useful for: - Reverse engineering: Given a file, what pattern does it belong to? - Validation: Does this file belong to a known pattern? - Discovery: What's the root directory of the pattern containing this file?</p> PARAMETER DESCRIPTION <code>file</code> <p>Path to a file to assess</p> <p> TYPE: <code>Path</code> </p> <code>patterns</code> <p>Patterns to check against</p> <p> TYPE: <code>Iterable[FileStructurePattern]</code> </p> YIELDS DESCRIPTION <code>ScanResult</code> <p>ScanResult objects with the root directory and matched pattern</p> Example <p>patterns = [pattern1, pattern2] for result in assess(Path(\"data/exp1/results.csv\"), patterns): ...     print(f\"File belongs to pattern at: {result.source}\")</p> Source code in <code>src/pathvein/lib.py</code> <pre><code>def assess(\n    file: Path,\n    patterns: Iterable[FileStructurePattern],\n) -&gt; Generator[ScanResult, None, None]:\n    \"\"\"Assess which patterns a file belongs to and find the pattern root directories.\n\n    Given a file path, this function determines which patterns it could belong to\n    by working backwards from the file to find candidate root directories, then\n    validating that those roots actually match the pattern.\n\n    This is useful for:\n    - Reverse engineering: Given a file, what pattern does it belong to?\n    - Validation: Does this file belong to a known pattern?\n    - Discovery: What's the root directory of the pattern containing this file?\n\n    Args:\n        file: Path to a file to assess\n        patterns: Patterns to check against\n\n    Yields:\n        ScanResult objects with the root directory and matched pattern\n\n    Example:\n        &gt;&gt;&gt; patterns = [pattern1, pattern2]\n        &gt;&gt;&gt; for result in assess(Path(\"data/exp1/results.csv\"), patterns):\n        ...     print(f\"File belongs to pattern at: {result.source}\")\n    \"\"\"\n    logger.debug(\"Assessing %s for patterns %s\", file, patterns)\n    for pattern in patterns:\n        logger.debug(\"Assessing %s for pattern %s\", file, pattern)\n        roots = pattern.parents_of(file)\n        logger.debug(\"Candidate root directories found: %s\", roots)\n        if len(roots) &gt; 0:\n            for root in roots:\n                if pattern.matches(iterdir(root)):\n                    logger.debug(\"Yielding root %s\", root)\n                    yield ScanResult(root, pattern)\n</code></pre>"},{"location":"api/functions/#shuffle","title":"shuffle","text":""},{"location":"api/functions/#pathvein.lib.shuffle","title":"pathvein.lib.shuffle","text":"<pre><code>shuffle(shuffle_def: Iterable[ShuffleInput], overwrite: bool = False, dryrun: bool = False, use_threading: bool = False, max_workers: int = 4) -&gt; List[ShuffleResult]\n</code></pre> <p>Recursively scan a source path for pattern-spec directory structures and copy them to their destination</p> <p>ShuffleInput.source will be copied to ShuffleInput.destination, not into it. The direct children of ShuffleInput.source will be direct children of ShuffleInput.destination</p> PARAMETER DESCRIPTION <code>shuffle_def</code> <p>Iterable of ShuffleInput defining source-&gt;destination mappings</p> <p> TYPE: <code>Iterable[ShuffleInput]</code> </p> <code>overwrite</code> <p>Whether to overwrite existing files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dryrun</code> <p>If True, don't actually copy files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_threading</code> <p>If True, use parallel file copying (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_workers</code> <p>Number of worker threads for parallel copying (default: 4)</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> Source code in <code>src/pathvein/lib.py</code> <pre><code>def shuffle(\n    shuffle_def: Iterable[ShuffleInput],\n    overwrite: bool = False,\n    dryrun: bool = False,\n    use_threading: bool = False,\n    max_workers: int = 4,\n) -&gt; List[ShuffleResult]:\n    \"\"\"\n    Recursively scan a source path for pattern-spec directory structures and copy them to their destination\n\n    ShuffleInput.source will be copied to ShuffleInput.destination, not _into_ it.\n    The direct children of ShuffleInput.source will be direct children of ShuffleInput.destination\n\n    Args:\n        shuffle_def: Iterable of ShuffleInput defining source-&gt;destination mappings\n        overwrite: Whether to overwrite existing files (default: False)\n        dryrun: If True, don't actually copy files (default: False)\n        use_threading: If True, use parallel file copying (default: False)\n        max_workers: Number of worker threads for parallel copying (default: 4)\n    \"\"\"\n\n    # Side effect time!\n    copied = []\n    for source, destination, pattern in shuffle_def:\n        try:\n            if use_threading:\n                pattern.threaded_copy(\n                    source,\n                    destination,\n                    overwrite=overwrite,\n                    dryrun=dryrun,\n                    max_workers=max_workers,\n                )\n            else:\n                pattern.copy(source, destination, overwrite=overwrite, dryrun=dryrun)\n            logger.debug(\"%s copied to %s\", source, destination)\n            copied.append(ShuffleResult(source, destination, pattern))\n        except FileExistsError:\n            logger.error(\n                \"Destination folder already exists: %s. Skipping: %s\",\n                destination,\n                source.name,\n            )\n    logger.info(\"Copied %s directories\", len(copied))\n    return copied\n</code></pre>"},{"location":"api/functions/#shuffle_to","title":"shuffle_to","text":""},{"location":"api/functions/#pathvein.lib.shuffle_to","title":"pathvein.lib.shuffle_to","text":"<pre><code>shuffle_to(matches: Iterable[ScanResult], destination: Path, overwrite: bool = False, dryrun: bool = False, use_threading: bool = False, max_workers: int = 4) -&gt; List[ShuffleResult]\n</code></pre> <p>Recursively scan a source path for pattern-spec directory structures and copy them into a single destination</p> <p>Each match will be copied into a flat structure at <code>destination / match.source.name</code></p> PARAMETER DESCRIPTION <code>matches</code> <p>Iterable of ScanResult from scan()</p> <p> TYPE: <code>Iterable[ScanResult]</code> </p> <code>destination</code> <p>Root destination directory</p> <p> TYPE: <code>Path</code> </p> <code>overwrite</code> <p>Whether to overwrite existing files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dryrun</code> <p>If True, don't actually copy files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_threading</code> <p>If True, use parallel file copying (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_workers</code> <p>Number of worker threads for parallel copying (default: 4)</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> Source code in <code>src/pathvein/lib.py</code> <pre><code>def shuffle_to(\n    matches: Iterable[ScanResult],\n    destination: Path,\n    overwrite: bool = False,\n    dryrun: bool = False,\n    use_threading: bool = False,\n    max_workers: int = 4,\n) -&gt; List[ShuffleResult]:\n    \"\"\"\n    Recursively scan a source path for pattern-spec directory structures and copy them into a single destination\n\n    Each match will be copied into a flat structure at `destination / match.source.name`\n\n    Args:\n        matches: Iterable of ScanResult from scan()\n        destination: Root destination directory\n        overwrite: Whether to overwrite existing files (default: False)\n        dryrun: If True, don't actually copy files (default: False)\n        use_threading: If True, use parallel file copying (default: False)\n        max_workers: Number of worker threads for parallel copying (default: 4)\n    \"\"\"\n\n    shuffle_def = map(\n        lambda match: ShuffleInput(\n            match.source, destination / match.source.name, match.pattern\n        ),\n        matches,\n    )\n    return shuffle(\n        shuffle_def,\n        overwrite=overwrite,\n        dryrun=dryrun,\n        use_threading=use_threading,\n        max_workers=max_workers,\n    )\n</code></pre>"},{"location":"api/functions/#shuffle_with","title":"shuffle_with","text":""},{"location":"api/functions/#pathvein.lib.shuffle_with","title":"pathvein.lib.shuffle_with","text":"<pre><code>shuffle_with(matches: Iterable[ScanResult], destination_fn: Callable[[ScanResult], Path], overwrite: bool = False, dryrun: bool = False, use_threading: bool = False, max_workers: int = 4) -&gt; List[ShuffleResult]\n</code></pre> <p>Recursively scan a source path for pattern-spec directory structures and copy them to computed destinations</p> <p>Provide a function that takes a ScanResult and returns a destination Path for that result. This allows for expressive control over the destination of each match.</p> PARAMETER DESCRIPTION <code>matches</code> <p>Iterable of ScanResult from scan()</p> <p> TYPE: <code>Iterable[ScanResult]</code> </p> <code>destination_fn</code> <p>Function that computes destination path from ScanResult</p> <p> TYPE: <code>Callable[[ScanResult], Path]</code> </p> <code>overwrite</code> <p>Whether to overwrite existing files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dryrun</code> <p>If True, don't actually copy files (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_threading</code> <p>If True, use parallel file copying (default: False)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_workers</code> <p>Number of worker threads for parallel copying (default: 4)</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> Source code in <code>src/pathvein/lib.py</code> <pre><code>def shuffle_with(\n    matches: Iterable[ScanResult],\n    destination_fn: Callable[[ScanResult], Path],\n    overwrite: bool = False,\n    dryrun: bool = False,\n    use_threading: bool = False,\n    max_workers: int = 4,\n) -&gt; List[ShuffleResult]:\n    \"\"\"\n    Recursively scan a source path for pattern-spec directory structures and copy them to computed destinations\n\n    Provide a function that takes a ScanResult and returns a destination Path for that result. This allows for\n    expressive control over the destination of each match.\n\n    Args:\n        matches: Iterable of ScanResult from scan()\n        destination_fn: Function that computes destination path from ScanResult\n        overwrite: Whether to overwrite existing files (default: False)\n        dryrun: If True, don't actually copy files (default: False)\n        use_threading: If True, use parallel file copying (default: False)\n        max_workers: Number of worker threads for parallel copying (default: 4)\n    \"\"\"\n\n    shuffle_def = map(\n        lambda scan_result: ShuffleInput(\n            scan_result.source, destination_fn(scan_result), scan_result.pattern\n        ),\n        matches,\n    )\n    return shuffle(\n        shuffle_def,\n        overwrite=overwrite,\n        dryrun=dryrun,\n        use_threading=use_threading,\n        max_workers=max_workers,\n    )\n</code></pre>"},{"location":"api/functions/#usage-examples","title":"Usage Examples","text":""},{"location":"api/functions/#scanning","title":"Scanning","text":"<pre><code>from pathlib import Path\nfrom pathvein import scan, FileStructurePattern\n\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"data.csv\"]\n)\n\nmatches = scan(\n    source=Path(\"data\"),\n    patterns=[pattern]\n)\n\nprint(f\"Found {len(matches)} matches\")\n</code></pre>"},{"location":"api/functions/#assessing","title":"Assessing","text":"<pre><code>from pathlib import Path\nfrom pathvein import assess, FileStructurePattern\n\npatterns = [\n    FileStructurePattern(directory_name=\"exp_*\", files=[\"*.csv\"]),\n    FileStructurePattern(directory_name=\"backup_*\", files=[\"*.csv\"])\n]\n\nfile = Path(\"data/exp_001/results.csv\")\n\nfor result in assess(file, patterns):\n    print(f\"Pattern: {result.pattern.directory_name}\")\n    print(f\"Root: {result.source}\")\n</code></pre>"},{"location":"api/functions/#shuffling","title":"Shuffling","text":"<pre><code>from pathlib import Path\nfrom pathvein import scan, shuffle_to, FileStructurePattern\n\n# Find matches\npattern = FileStructurePattern(files=[\"*.csv\"])\nmatches = scan(Path(\"data\"), [pattern])\n\n# Copy to destination\nresults = shuffle_to(\n    matches=matches,\n    destination=Path(\"organized\"),\n    overwrite=False,\n    dryrun=False\n)\n\nprint(f\"Copied {len(results)} directories\")\n</code></pre>"},{"location":"api/pattern/","title":"FileStructurePattern","text":"<p>The <code>FileStructurePattern</code> class is the core of pathvein's pattern matching system.</p>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern","title":"pathvein.pattern.FileStructurePattern  <code>dataclass</code>","text":"<p>A representation of a file structure pattern with required and optional components.</p> <p>This class also supports a builder pattern as any intermediate state is also valid.</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>@dataclass\nclass FileStructurePattern:\n    \"\"\"\n    A representation of a file structure pattern with required and optional components.\n\n    This class also supports a builder pattern as any intermediate state is also valid.\n    \"\"\"\n\n    directory_name: str = \"*\"\n    files: List[str] = field(default_factory=list)\n    directories: List[Self] = field(default_factory=list)\n    optional_files: List[str] = field(default_factory=list)\n    optional_directories: List[Self] = field(default_factory=list)\n\n    def __key(self: Self):\n        return (\n            self.directory_name,\n            hash(tuple(self.files)),\n            hash(tuple(self.directories)),\n            hash(tuple(self.optional_files)),\n            hash(tuple(self.optional_directories)),\n        )\n\n    def __hash__(self: Self):\n        return hash(self.__key())\n\n    def __eq__(self: Self, other: Any):\n        if isinstance(other, FileStructurePattern):\n            return self.__key() == other.__key()\n        return NotImplemented\n\n    @classmethod\n    def load_json(cls, json_path: Path) -&gt; Self:\n        \"\"\"Load a FileStructurePattern from a JSON file\n\n        Args:\n            json_path: Path to JSON file containing pattern specification\n\n        Returns:\n            FileStructurePattern instance\n\n        Raises:\n            FileNotFoundError: If json_path does not exist\n            json.JSONDecodeError: If file contains invalid JSON\n            ValueError: If JSON structure is invalid for pattern specification\n        \"\"\"\n        try:\n            json_str = json_path.read_text()\n        except FileNotFoundError as e:\n            raise FileNotFoundError(f\"Pattern file not found: {json_path}\") from e\n        except Exception as e:\n            raise ValueError(f\"Error reading pattern file {json_path}: {e}\") from e\n        return cls.from_json(json_str)\n\n    @classmethod\n    def from_json(cls, spec_str: str) -&gt; Self:\n        \"\"\"Create a FileStructurePattern from a JSON string\n\n        Args:\n            spec_str: JSON string containing pattern specification\n\n        Returns:\n            FileStructurePattern instance\n\n        Raises:\n            json.JSONDecodeError: If spec_str is not valid JSON\n            ValueError: If JSON structure is invalid for pattern specification\n        \"\"\"\n        try:\n            spec = json.loads(spec_str)\n        except json.JSONDecodeError as e:\n            raise json.JSONDecodeError(\n                f\"Invalid JSON in pattern specification: {e.msg}\", e.doc, e.pos\n            ) from e\n\n        if not isinstance(spec, dict):\n            raise ValueError(\n                f\"Pattern specification must be a JSON object, got {type(spec).__name__}\"\n            )\n\n        try:\n            return (\n                cls()\n                .set_directory_name(spec.get(\"directory_name\", \"*\"))\n                .add_files(spec.get(\"files\", []))\n                .add_files(spec.get(\"optional_files\", []), is_optional=True)\n                .add_directories(\n                    (\n                        cls.from_json(subdirectory_spec)\n                        for subdirectory_spec in spec.get(\"directories\", [])\n                    )\n                )\n                .add_directories(\n                    (\n                        cls.from_json(subdirectory_spec)\n                        for subdirectory_spec in spec.get(\"optional_directories\", [])\n                    ),\n                    is_optional=True,\n                )\n            )\n        except (TypeError, AttributeError) as e:\n            raise ValueError(f\"Invalid pattern specification structure: {e}\") from e\n\n    def to_json(self: Self) -&gt; str:\n        # Deepcopy prevents mutating self during serialization.\n        # self__dict__ and dictionary point to the same object otherwise.\n        dictionary = deepcopy(self.__dict__)\n        dictionary[\"directories\"] = [\n            directory.to_json() for directory in self.directories\n        ]\n        dictionary[\"optional_directories\"] = [\n            directory.to_json() for directory in self.optional_directories\n        ]\n        return json.dumps(dictionary)\n\n    def add_directory(self: Self, directory: Self, is_optional: bool = False) -&gt; Self:\n        \"\"\"\n        Add a FileStructureRequirement entry to the (optional) directory list\n\n        This method uses deepcopy to prevent recursive references. This means it supports\n        ```python\n        requirement = FileStructureRequirement()\n        requirement.add_directory(requirement)\n        ```\n        This keeps the two requirements as separate objects so as to not create a reference loop.\n        \"\"\"\n        if is_optional:\n            self.optional_directories.append(deepcopy(directory))\n        else:\n            self.directories.append(deepcopy(directory))\n        return self\n\n    def add_directories(\n        self: Self, directories: Iterable[Self], is_optional: bool = False\n    ) -&gt; Self:\n        for directory in directories:\n            self.add_directory(directory, is_optional)\n        return self\n\n    def add_file(self: Self, file: str, is_optional: bool = False) -&gt; Self:\n        if is_optional:\n            self.optional_files.append(file)\n        else:\n            self.files.append(file)\n        return self\n\n    def add_files(self: Self, files: Iterable[str], is_optional: bool = False) -&gt; Self:\n        for file in files:\n            self.add_file(file, is_optional)\n        return self\n\n    def set_directory_name(self: Self, name: str) -&gt; Self:\n        self.directory_name = name\n        return self\n\n    @property\n    def all_files(self: Self) -&gt; List[str]:\n        return list(set(self.files) | set(self.optional_files))\n\n    @property\n    def all_directories(self: Self) -&gt; List[Self]:\n        return list(set(self.directories) | set(self.optional_directories))\n\n    def parents_of(self: Self, file: Path, parent: Path = Path()) -&gt; Set[Path]:\n        \"\"\"Find all possible parent directories that could contain the given file based on the pattern.\n\n        This method will complete a recursive search through all the required and\n        optional files in the pattern through all directory tree branches.\n\n        Each level constructs the pattern for the optional and required files\n        to include the parents of the current directory pattern and compares that\n        to the full path of the provided file. If the pattern matches then we\n        compute the root directory of the pattern that would contain that file by\n        evaluating the depth of the pattern and backing off that many layers from\n        the input file. That path gets added to a set of possible parent directories.\n\n        Its possible to have multiple possible parent directories at this point of\n        evaluation. As a trivial example imagine a pattern with optional files at\n        **/a/b/file.txt and **/b/file.txt. When provided an input file of:\n\n        /input/a/b/file.txt it will match on both patterns. The two possible parent\n        or root directories are /input and /input/a. Without evaluating the full\n        pattern from that root directory we cannot yet be sure if either is actually\n        a valid parent/root directory. We only have the context of this single input\n        file. From that alone, either directory _could_ be the root with this pattern.\n        \"\"\"\n        candidates = set()\n        prefix = \"**/\"\n        for file_pattern in self.all_files:\n            pattern = prefix + str(parent / file_pattern)\n            # UPath.match doesn't seem to work reliably, cast to a Path type explicitly\n            # and use its glob-style pattern matching.\n            # This turns s3://bucket/prefix into /bucket/prefix so any glob pattern as\n            # the only difference is the absence of the s3:/ protocol prefix.\n            if Path(file).match(pattern):\n                # patterns are ** / &lt;directories&gt; / file\n                # so the directory depth is length of parts - 2\n                # Minus 1 for the ** and minus 1 for the file\n                # The directory depth is the number of \"parents\" that we need to go up.\n                depth = len(Path(pattern).parts) - 2\n                candidates.add(file.parents[depth])\n\n        for directory in self.all_directories:\n            candidates |= directory.parents_of(file, parent / directory.directory_name)\n\n        return candidates\n\n    def matches(\n        self: Self, walk_args: Tuple[Path, List[str], List[str]], depth: int = 1\n    ) -&gt; bool:\n        \"\"\"Check if a provided dirpath, dirnames, and filenames set matches the requirements\"\"\"\n\n        # Unpack Path.walk outputs. Taking this as a tuple simplifies the recursion callsite below\n        dirpath, dirnames, filenames = walk_args\n\n        lpad = \"#\" * depth\n\n        logger.debug(\"%s Evaluating match for %s against %s\", lpad, dirpath, self)\n\n        # Short circuit check for directory name pattern match\n        if self.directory_name and not match_pattern(dirpath.name, self.directory_name):\n            logger.debug(\n                \"%s x Failed match on directory name: Expected: %s, Found: %s\",\n                lpad,\n                self.directory_name,\n                dirpath,\n            )\n            return False\n\n        # Short circuit check for required file patterns\n        for pattern in self.files:\n            # If all input filenames do not match a pattern, then its a missed pattern, and not a match\n            # The failing case is when no files match a pattern, aka all files do not match.\n            #\n            # NOTE(Performance): Use PatternMatcher to avoid FFI overhead on each filename check\n            # PatternMatcher compiles the pattern once and keeps it in Rust, avoiding repeated FFI calls\n            # Invalid patterns are automatically handled by PatternMatcher (falls back to Python)\n            matcher = PatternMatcher([pattern])\n            if _none_of(matcher.matches(filename) for filename in filenames):\n                logger.debug(\n                    \"%s x Failed match on required file pattern. Required %s, Found: %s, Directory: %s\",\n                    lpad,\n                    pattern,\n                    filenames,\n                    dirpath,\n                )\n                return False\n\n        # NOTE: This could be written as a double nested list comprehension that includes the\n        # self.directories iterations as well, but its rather confusing to read, leaving that\n        # as an outer for-loop is easier to read.\n        #\n        # Recurse into required subdirectory branches (if they exist)\n        for branch_pattern in self.directories:\n            # Evaluate if any actual directories from dirnames match the given pattern\n            if _none_of(\n                branch_pattern.matches(iterdir(dirpath / directory), depth + 1)\n                for directory in dirnames\n            ):\n                logger.debug(\n                    \"%s x Failed on subdirectory match. Required %s, Found: %s, Directory: %s\",\n                    lpad,\n                    branch_pattern,\n                    dirnames,\n                    dirpath,\n                )\n                return False\n\n        # Passing all previous checks implies:\n        # 1. The directory_name matches or is not a requirement\n        # 2. The required file patterns are matched\n        # 3. The required directories are matched (recursively)\n        # In this case, this directory structure meets the requirements!\n        logger.info(\"%s + Matched: %s on %s!\", lpad, dirpath, self)\n        return True\n\n    def copy(\n        self: Self,\n        source: Path,\n        destination: Path,\n        overwrite: bool = False,\n        dryrun: bool = False,\n    ) -&gt; None:\n        \"\"\"Copy all files and folders from inside source that match the file requirements patterns into the destination path.\n\n        Before:\n        Source:\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n\n        Destination:\n        dest_dir/\n\n        After:\n        Source:\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n\n        Destination:\n        dest_dir/\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n        \"\"\"\n        start_time = time()\n\n        dryrun_pad = \"(dryrun) \" if dryrun else \"\"\n\n        if not dryrun:\n            destination.mkdir(parents=True, exist_ok=overwrite)\n        # Copy all files in this top level that match a required or optional file pattern\n        _, directories, files = iterdir(source)\n        # Use PatternMatcher for efficient multi-pattern matching\n        file_matcher = PatternMatcher(self.all_files) if self.all_files else None\n        for file in files:\n            path = source / file\n            logger.debug(\n                \"Checking file against patterns\",\n                extra={\"file\": file, \"pattern\": self.all_files},\n            )\n            if file_matcher and file_matcher.matches(path.name):\n                logger.debug(\"Found match\")\n                if not dryrun:\n                    logger.debug(\"Beginning copy\")\n                    target = destination / path.name\n                    stream_copy(path, target)\n                    logger.debug(\n                        \"Copied file\",\n                        extra={\n                            \"file\": path.as_posix(),\n                            \"destination\": destination / path.name,\n                        },\n                    )\n        # Recurse into any directories at this level that match a required or optional directory pattern\n        for directory in directories:\n            path = source / directory\n            for branch_pattern in self.all_directories:\n                if branch_pattern.matches(iterdir(path)):\n                    branch_pattern.copy(\n                        path,\n                        destination / path.name,\n                        overwrite=overwrite,\n                        dryrun=dryrun,\n                    )\n\n        logger.info(\n            \"%s Directory copied\",\n            dryrun_pad,\n            extra={\n                \"source\": source,\n                \"destination\": destination,\n                \"duration\": time() - start_time,\n            },\n        )\n\n    def threaded_copy(\n        self: Self,\n        source: Path,\n        destination: Path,\n        overwrite: bool = False,\n        dryrun: bool = False,\n        max_workers: int = 4,\n    ) -&gt; None:\n        \"\"\"Copy all files and folders from inside source that match the file requirements patterns into the destination path.\n\n        Before:\n        Source:\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n\n        Destination:\n        dest_dir/\n\n        After:\n        Source:\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n\n        Destination:\n        dest_dir/\n        source_dir/\n            file1.txt\n            nested/\n                file2.txt\n        \"\"\"\n        start_time = time()\n\n        futures: Set[Future] = set()\n        with ThreadPoolExecutor(\n            max_workers=max_workers\n        ) as executor:  # Adjust based on your needs\n\n            def recursive_scan(src: Path, dest: Path, pattern: Self = self):\n                if not dryrun:\n                    dest.mkdir(parents=True, exist_ok=overwrite)\n                # Copy all files in this top level that match a required or optional file pattern\n                _, directories, files = iterdir(src)\n                # Use PatternMatcher for efficient multi-pattern matching\n                file_matcher = (\n                    PatternMatcher(pattern.all_files) if pattern.all_files else None\n                )\n                logger.debug(\n                    \"Beginning copy operation\",\n                    extra={\n                        \"source\": src,\n                        \"directories\": directories,\n                        \"files\": files,\n                        \"pattern\": pattern,\n                    },\n                )\n                for file in files:\n                    path = src / file\n                    logger.debug(\n                        \"Checking file against patterns\",\n                        extra={\"file\": path.name, \"pattern\": pattern.all_files},\n                    )\n                    if file_matcher and file_matcher.matches(path.name):\n                        logger.debug(\"Found match\")\n                        if not dryrun:\n                            target = dest / path.name\n                            logger.debug(\n                                \"Submitting copy task\",\n                                extra={\"source\": path, \"destination\": target},\n                            )\n                            future = executor.submit(stream_copy, path, target)\n                            futures.add(future)\n                # Recurse into any directories at this level that match a required or optional directory pattern\n                for directory in directories:\n                    path = src / directory\n                    for branch_pattern in self.all_directories:\n                        if branch_pattern.matches(iterdir(path)):\n                            recursive_scan(path, dest / path.name, branch_pattern)\n\n            recursive_scan(source, destination)\n\n            logger.debug(\"Waiting for futures\", extra={\"count\": len(futures)})\n            done, _ = wait(futures)\n            for future in done:\n                try:\n                    future.result()\n                except Exception as e:\n                    logger.error(\"Copy operation failed\", exc_info=e)\n\n        logger.info(\n            \"%s Directory copied\",\n            \"(dryrun) \" if dryrun else \"\",\n            extra={\n                \"source\": source,\n                \"destination\": destination,\n                \"duration\": time() - start_time,\n            },\n        )\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern-attributes","title":"Attributes","text":""},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.all_files","title":"all_files  <code>property</code>","text":"<pre><code>all_files: List[str]\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.all_directories","title":"all_directories  <code>property</code>","text":"<pre><code>all_directories: List[Self]\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern-functions","title":"Functions","text":""},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.__init__","title":"__init__","text":"<pre><code>__init__(directory_name: str = '*', files: List[str] = list(), directories: List[Self] = list(), optional_files: List[str] = list(), optional_directories: List[Self] = list()) -&gt; None\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.load_json","title":"load_json  <code>classmethod</code>","text":"<pre><code>load_json(json_path: Path) -&gt; Self\n</code></pre> <p>Load a FileStructurePattern from a JSON file</p> PARAMETER DESCRIPTION <code>json_path</code> <p>Path to JSON file containing pattern specification</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>FileStructurePattern instance</p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If json_path does not exist</p> <code>JSONDecodeError</code> <p>If file contains invalid JSON</p> <code>ValueError</code> <p>If JSON structure is invalid for pattern specification</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>@classmethod\ndef load_json(cls, json_path: Path) -&gt; Self:\n    \"\"\"Load a FileStructurePattern from a JSON file\n\n    Args:\n        json_path: Path to JSON file containing pattern specification\n\n    Returns:\n        FileStructurePattern instance\n\n    Raises:\n        FileNotFoundError: If json_path does not exist\n        json.JSONDecodeError: If file contains invalid JSON\n        ValueError: If JSON structure is invalid for pattern specification\n    \"\"\"\n    try:\n        json_str = json_path.read_text()\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"Pattern file not found: {json_path}\") from e\n    except Exception as e:\n        raise ValueError(f\"Error reading pattern file {json_path}: {e}\") from e\n    return cls.from_json(json_str)\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(spec_str: str) -&gt; Self\n</code></pre> <p>Create a FileStructurePattern from a JSON string</p> PARAMETER DESCRIPTION <code>spec_str</code> <p>JSON string containing pattern specification</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>FileStructurePattern instance</p> RAISES DESCRIPTION <code>JSONDecodeError</code> <p>If spec_str is not valid JSON</p> <code>ValueError</code> <p>If JSON structure is invalid for pattern specification</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>@classmethod\ndef from_json(cls, spec_str: str) -&gt; Self:\n    \"\"\"Create a FileStructurePattern from a JSON string\n\n    Args:\n        spec_str: JSON string containing pattern specification\n\n    Returns:\n        FileStructurePattern instance\n\n    Raises:\n        json.JSONDecodeError: If spec_str is not valid JSON\n        ValueError: If JSON structure is invalid for pattern specification\n    \"\"\"\n    try:\n        spec = json.loads(spec_str)\n    except json.JSONDecodeError as e:\n        raise json.JSONDecodeError(\n            f\"Invalid JSON in pattern specification: {e.msg}\", e.doc, e.pos\n        ) from e\n\n    if not isinstance(spec, dict):\n        raise ValueError(\n            f\"Pattern specification must be a JSON object, got {type(spec).__name__}\"\n        )\n\n    try:\n        return (\n            cls()\n            .set_directory_name(spec.get(\"directory_name\", \"*\"))\n            .add_files(spec.get(\"files\", []))\n            .add_files(spec.get(\"optional_files\", []), is_optional=True)\n            .add_directories(\n                (\n                    cls.from_json(subdirectory_spec)\n                    for subdirectory_spec in spec.get(\"directories\", [])\n                )\n            )\n            .add_directories(\n                (\n                    cls.from_json(subdirectory_spec)\n                    for subdirectory_spec in spec.get(\"optional_directories\", [])\n                ),\n                is_optional=True,\n            )\n        )\n    except (TypeError, AttributeError) as e:\n        raise ValueError(f\"Invalid pattern specification structure: {e}\") from e\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def to_json(self: Self) -&gt; str:\n    # Deepcopy prevents mutating self during serialization.\n    # self__dict__ and dictionary point to the same object otherwise.\n    dictionary = deepcopy(self.__dict__)\n    dictionary[\"directories\"] = [\n        directory.to_json() for directory in self.directories\n    ]\n    dictionary[\"optional_directories\"] = [\n        directory.to_json() for directory in self.optional_directories\n    ]\n    return json.dumps(dictionary)\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.add_directory","title":"add_directory","text":"<pre><code>add_directory(directory: Self, is_optional: bool = False) -&gt; Self\n</code></pre> <p>Add a FileStructureRequirement entry to the (optional) directory list</p> <p>This method uses deepcopy to prevent recursive references. This means it supports <pre><code>requirement = FileStructureRequirement()\nrequirement.add_directory(requirement)\n</code></pre> This keeps the two requirements as separate objects so as to not create a reference loop.</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def add_directory(self: Self, directory: Self, is_optional: bool = False) -&gt; Self:\n    \"\"\"\n    Add a FileStructureRequirement entry to the (optional) directory list\n\n    This method uses deepcopy to prevent recursive references. This means it supports\n    ```python\n    requirement = FileStructureRequirement()\n    requirement.add_directory(requirement)\n    ```\n    This keeps the two requirements as separate objects so as to not create a reference loop.\n    \"\"\"\n    if is_optional:\n        self.optional_directories.append(deepcopy(directory))\n    else:\n        self.directories.append(deepcopy(directory))\n    return self\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.add_directories","title":"add_directories","text":"<pre><code>add_directories(directories: Iterable[Self], is_optional: bool = False) -&gt; Self\n</code></pre> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def add_directories(\n    self: Self, directories: Iterable[Self], is_optional: bool = False\n) -&gt; Self:\n    for directory in directories:\n        self.add_directory(directory, is_optional)\n    return self\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.add_file","title":"add_file","text":"<pre><code>add_file(file: str, is_optional: bool = False) -&gt; Self\n</code></pre> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def add_file(self: Self, file: str, is_optional: bool = False) -&gt; Self:\n    if is_optional:\n        self.optional_files.append(file)\n    else:\n        self.files.append(file)\n    return self\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.add_files","title":"add_files","text":"<pre><code>add_files(files: Iterable[str], is_optional: bool = False) -&gt; Self\n</code></pre> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def add_files(self: Self, files: Iterable[str], is_optional: bool = False) -&gt; Self:\n    for file in files:\n        self.add_file(file, is_optional)\n    return self\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.set_directory_name","title":"set_directory_name","text":"<pre><code>set_directory_name(name: str) -&gt; Self\n</code></pre> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def set_directory_name(self: Self, name: str) -&gt; Self:\n    self.directory_name = name\n    return self\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.parents_of","title":"parents_of","text":"<pre><code>parents_of(file: Path, parent: Path = Path()) -&gt; Set[Path]\n</code></pre> <p>Find all possible parent directories that could contain the given file based on the pattern.</p> <p>This method will complete a recursive search through all the required and optional files in the pattern through all directory tree branches.</p> <p>Each level constructs the pattern for the optional and required files to include the parents of the current directory pattern and compares that to the full path of the provided file. If the pattern matches then we compute the root directory of the pattern that would contain that file by evaluating the depth of the pattern and backing off that many layers from the input file. That path gets added to a set of possible parent directories.</p> <p>Its possible to have multiple possible parent directories at this point of evaluation. As a trivial example imagine a pattern with optional files at /a/b/file.txt and /b/file.txt. When provided an input file of:</p> <p>/input/a/b/file.txt it will match on both patterns. The two possible parent or root directories are /input and /input/a. Without evaluating the full pattern from that root directory we cannot yet be sure if either is actually a valid parent/root directory. We only have the context of this single input file. From that alone, either directory could be the root with this pattern.</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def parents_of(self: Self, file: Path, parent: Path = Path()) -&gt; Set[Path]:\n    \"\"\"Find all possible parent directories that could contain the given file based on the pattern.\n\n    This method will complete a recursive search through all the required and\n    optional files in the pattern through all directory tree branches.\n\n    Each level constructs the pattern for the optional and required files\n    to include the parents of the current directory pattern and compares that\n    to the full path of the provided file. If the pattern matches then we\n    compute the root directory of the pattern that would contain that file by\n    evaluating the depth of the pattern and backing off that many layers from\n    the input file. That path gets added to a set of possible parent directories.\n\n    Its possible to have multiple possible parent directories at this point of\n    evaluation. As a trivial example imagine a pattern with optional files at\n    **/a/b/file.txt and **/b/file.txt. When provided an input file of:\n\n    /input/a/b/file.txt it will match on both patterns. The two possible parent\n    or root directories are /input and /input/a. Without evaluating the full\n    pattern from that root directory we cannot yet be sure if either is actually\n    a valid parent/root directory. We only have the context of this single input\n    file. From that alone, either directory _could_ be the root with this pattern.\n    \"\"\"\n    candidates = set()\n    prefix = \"**/\"\n    for file_pattern in self.all_files:\n        pattern = prefix + str(parent / file_pattern)\n        # UPath.match doesn't seem to work reliably, cast to a Path type explicitly\n        # and use its glob-style pattern matching.\n        # This turns s3://bucket/prefix into /bucket/prefix so any glob pattern as\n        # the only difference is the absence of the s3:/ protocol prefix.\n        if Path(file).match(pattern):\n            # patterns are ** / &lt;directories&gt; / file\n            # so the directory depth is length of parts - 2\n            # Minus 1 for the ** and minus 1 for the file\n            # The directory depth is the number of \"parents\" that we need to go up.\n            depth = len(Path(pattern).parts) - 2\n            candidates.add(file.parents[depth])\n\n    for directory in self.all_directories:\n        candidates |= directory.parents_of(file, parent / directory.directory_name)\n\n    return candidates\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.matches","title":"matches","text":"<pre><code>matches(walk_args: Tuple[Path, List[str], List[str]], depth: int = 1) -&gt; bool\n</code></pre> <p>Check if a provided dirpath, dirnames, and filenames set matches the requirements</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def matches(\n    self: Self, walk_args: Tuple[Path, List[str], List[str]], depth: int = 1\n) -&gt; bool:\n    \"\"\"Check if a provided dirpath, dirnames, and filenames set matches the requirements\"\"\"\n\n    # Unpack Path.walk outputs. Taking this as a tuple simplifies the recursion callsite below\n    dirpath, dirnames, filenames = walk_args\n\n    lpad = \"#\" * depth\n\n    logger.debug(\"%s Evaluating match for %s against %s\", lpad, dirpath, self)\n\n    # Short circuit check for directory name pattern match\n    if self.directory_name and not match_pattern(dirpath.name, self.directory_name):\n        logger.debug(\n            \"%s x Failed match on directory name: Expected: %s, Found: %s\",\n            lpad,\n            self.directory_name,\n            dirpath,\n        )\n        return False\n\n    # Short circuit check for required file patterns\n    for pattern in self.files:\n        # If all input filenames do not match a pattern, then its a missed pattern, and not a match\n        # The failing case is when no files match a pattern, aka all files do not match.\n        #\n        # NOTE(Performance): Use PatternMatcher to avoid FFI overhead on each filename check\n        # PatternMatcher compiles the pattern once and keeps it in Rust, avoiding repeated FFI calls\n        # Invalid patterns are automatically handled by PatternMatcher (falls back to Python)\n        matcher = PatternMatcher([pattern])\n        if _none_of(matcher.matches(filename) for filename in filenames):\n            logger.debug(\n                \"%s x Failed match on required file pattern. Required %s, Found: %s, Directory: %s\",\n                lpad,\n                pattern,\n                filenames,\n                dirpath,\n            )\n            return False\n\n    # NOTE: This could be written as a double nested list comprehension that includes the\n    # self.directories iterations as well, but its rather confusing to read, leaving that\n    # as an outer for-loop is easier to read.\n    #\n    # Recurse into required subdirectory branches (if they exist)\n    for branch_pattern in self.directories:\n        # Evaluate if any actual directories from dirnames match the given pattern\n        if _none_of(\n            branch_pattern.matches(iterdir(dirpath / directory), depth + 1)\n            for directory in dirnames\n        ):\n            logger.debug(\n                \"%s x Failed on subdirectory match. Required %s, Found: %s, Directory: %s\",\n                lpad,\n                branch_pattern,\n                dirnames,\n                dirpath,\n            )\n            return False\n\n    # Passing all previous checks implies:\n    # 1. The directory_name matches or is not a requirement\n    # 2. The required file patterns are matched\n    # 3. The required directories are matched (recursively)\n    # In this case, this directory structure meets the requirements!\n    logger.info(\"%s + Matched: %s on %s!\", lpad, dirpath, self)\n    return True\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.copy","title":"copy","text":"<pre><code>copy(source: Path, destination: Path, overwrite: bool = False, dryrun: bool = False) -&gt; None\n</code></pre> <p>Copy all files and folders from inside source that match the file requirements patterns into the destination path.</p> <p>Before: Source: source_dir/     file1.txt     nested/         file2.txt</p> <p>Destination: dest_dir/</p> <p>After: Source: source_dir/     file1.txt     nested/         file2.txt</p> <p>Destination: dest_dir/ source_dir/     file1.txt     nested/         file2.txt</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def copy(\n    self: Self,\n    source: Path,\n    destination: Path,\n    overwrite: bool = False,\n    dryrun: bool = False,\n) -&gt; None:\n    \"\"\"Copy all files and folders from inside source that match the file requirements patterns into the destination path.\n\n    Before:\n    Source:\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n\n    Destination:\n    dest_dir/\n\n    After:\n    Source:\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n\n    Destination:\n    dest_dir/\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n    \"\"\"\n    start_time = time()\n\n    dryrun_pad = \"(dryrun) \" if dryrun else \"\"\n\n    if not dryrun:\n        destination.mkdir(parents=True, exist_ok=overwrite)\n    # Copy all files in this top level that match a required or optional file pattern\n    _, directories, files = iterdir(source)\n    # Use PatternMatcher for efficient multi-pattern matching\n    file_matcher = PatternMatcher(self.all_files) if self.all_files else None\n    for file in files:\n        path = source / file\n        logger.debug(\n            \"Checking file against patterns\",\n            extra={\"file\": file, \"pattern\": self.all_files},\n        )\n        if file_matcher and file_matcher.matches(path.name):\n            logger.debug(\"Found match\")\n            if not dryrun:\n                logger.debug(\"Beginning copy\")\n                target = destination / path.name\n                stream_copy(path, target)\n                logger.debug(\n                    \"Copied file\",\n                    extra={\n                        \"file\": path.as_posix(),\n                        \"destination\": destination / path.name,\n                    },\n                )\n    # Recurse into any directories at this level that match a required or optional directory pattern\n    for directory in directories:\n        path = source / directory\n        for branch_pattern in self.all_directories:\n            if branch_pattern.matches(iterdir(path)):\n                branch_pattern.copy(\n                    path,\n                    destination / path.name,\n                    overwrite=overwrite,\n                    dryrun=dryrun,\n                )\n\n    logger.info(\n        \"%s Directory copied\",\n        dryrun_pad,\n        extra={\n            \"source\": source,\n            \"destination\": destination,\n            \"duration\": time() - start_time,\n        },\n    )\n</code></pre>"},{"location":"api/pattern/#pathvein.pattern.FileStructurePattern.threaded_copy","title":"threaded_copy","text":"<pre><code>threaded_copy(source: Path, destination: Path, overwrite: bool = False, dryrun: bool = False, max_workers: int = 4) -&gt; None\n</code></pre> <p>Copy all files and folders from inside source that match the file requirements patterns into the destination path.</p> <p>Before: Source: source_dir/     file1.txt     nested/         file2.txt</p> <p>Destination: dest_dir/</p> <p>After: Source: source_dir/     file1.txt     nested/         file2.txt</p> <p>Destination: dest_dir/ source_dir/     file1.txt     nested/         file2.txt</p> Source code in <code>src/pathvein/pattern.py</code> <pre><code>def threaded_copy(\n    self: Self,\n    source: Path,\n    destination: Path,\n    overwrite: bool = False,\n    dryrun: bool = False,\n    max_workers: int = 4,\n) -&gt; None:\n    \"\"\"Copy all files and folders from inside source that match the file requirements patterns into the destination path.\n\n    Before:\n    Source:\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n\n    Destination:\n    dest_dir/\n\n    After:\n    Source:\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n\n    Destination:\n    dest_dir/\n    source_dir/\n        file1.txt\n        nested/\n            file2.txt\n    \"\"\"\n    start_time = time()\n\n    futures: Set[Future] = set()\n    with ThreadPoolExecutor(\n        max_workers=max_workers\n    ) as executor:  # Adjust based on your needs\n\n        def recursive_scan(src: Path, dest: Path, pattern: Self = self):\n            if not dryrun:\n                dest.mkdir(parents=True, exist_ok=overwrite)\n            # Copy all files in this top level that match a required or optional file pattern\n            _, directories, files = iterdir(src)\n            # Use PatternMatcher for efficient multi-pattern matching\n            file_matcher = (\n                PatternMatcher(pattern.all_files) if pattern.all_files else None\n            )\n            logger.debug(\n                \"Beginning copy operation\",\n                extra={\n                    \"source\": src,\n                    \"directories\": directories,\n                    \"files\": files,\n                    \"pattern\": pattern,\n                },\n            )\n            for file in files:\n                path = src / file\n                logger.debug(\n                    \"Checking file against patterns\",\n                    extra={\"file\": path.name, \"pattern\": pattern.all_files},\n                )\n                if file_matcher and file_matcher.matches(path.name):\n                    logger.debug(\"Found match\")\n                    if not dryrun:\n                        target = dest / path.name\n                        logger.debug(\n                            \"Submitting copy task\",\n                            extra={\"source\": path, \"destination\": target},\n                        )\n                        future = executor.submit(stream_copy, path, target)\n                        futures.add(future)\n            # Recurse into any directories at this level that match a required or optional directory pattern\n            for directory in directories:\n                path = src / directory\n                for branch_pattern in self.all_directories:\n                    if branch_pattern.matches(iterdir(path)):\n                        recursive_scan(path, dest / path.name, branch_pattern)\n\n        recursive_scan(source, destination)\n\n        logger.debug(\"Waiting for futures\", extra={\"count\": len(futures)})\n        done, _ = wait(futures)\n        for future in done:\n            try:\n                future.result()\n            except Exception as e:\n                logger.error(\"Copy operation failed\", exc_info=e)\n\n    logger.info(\n        \"%s Directory copied\",\n        \"(dryrun) \" if dryrun else \"\",\n        extra={\n            \"source\": source,\n            \"destination\": destination,\n            \"duration\": time() - start_time,\n        },\n    )\n</code></pre>"},{"location":"api/pattern/#usage-examples","title":"Usage Examples","text":""},{"location":"api/pattern/#creating-patterns","title":"Creating Patterns","text":"<pre><code>from pathvein import FileStructurePattern\n\n# Constructor\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"config.yaml\", \"data.csv\"],\n    optional_files=[\"notes.txt\"]\n)\n\n# Builder pattern\npattern = (\n    FileStructurePattern()\n    .set_directory_name(\"exp_*\")\n    .add_file(\"config.yaml\")\n    .add_files([\"data.csv\", \"results.csv\"])\n    .add_file(\"notes.txt\", is_optional=True)\n)\n</code></pre>"},{"location":"api/pattern/#nested-patterns","title":"Nested Patterns","text":"<pre><code>src_pattern = FileStructurePattern(\n    directory_name=\"src\",\n    files=[\"__init__.py\"]\n)\n\nproject_pattern = FileStructurePattern(\n    directory_name=\"my_project\",\n    files=[\"README.md\"],\n    directories=[src_pattern]\n)\n</code></pre>"},{"location":"api/pattern/#json-serialization","title":"JSON Serialization","text":"<pre><code>from pathlib import Path\n\n# Save\njson_str = pattern.to_json()\nPath(\"pattern.json\").write_text(json_str)\n\n# Load from file\npattern = FileStructurePattern.load_json(Path(\"pattern.json\"))\n\n# Load from string\npattern = FileStructurePattern.from_json(json_str)\n</code></pre>"},{"location":"api/pattern/#pattern-matching","title":"Pattern Matching","text":"<pre><code>from pathlib import Path\nfrom pathvein._path_utils import iterdir\n\npath = Path(\"data/experiment_001\")\ndirpath, dirnames, filenames = iterdir(path)\n\nif pattern.matches((dirpath, dirnames, filenames)):\n    print(\"Match!\")\n</code></pre>"},{"location":"api/pattern/#finding-parent-directories","title":"Finding Parent Directories","text":"<pre><code>from pathlib import Path\n\nfile = Path(\"data/experiment_001/results.csv\")\ncandidates = pattern.parents_of(file)\n\nfor candidate in candidates:\n    print(f\"Possible root: {candidate}\")\n</code></pre>"},{"location":"api/pattern/#copying-with-patterns","title":"Copying with Patterns","text":"<pre><code>from pathlib import Path\n\n# Single-threaded copy\npattern.copy(\n    source=Path(\"data/exp_001\"),\n    destination=Path(\"backup/exp_001\"),\n    overwrite=False,\n    dryrun=False\n)\n\n# Multi-threaded copy (faster for many small files)\npattern.threaded_copy(\n    source=Path(\"data/exp_001\"),\n    destination=Path(\"backup/exp_001\"),\n    overwrite=False,\n    dryrun=False,\n    max_workers=4\n)\n</code></pre>"},{"location":"api/pattern/#pattern-components","title":"Pattern Components","text":""},{"location":"api/pattern/#directory_name","title":"directory_name","text":"<p>Glob pattern for the directory name. Default: <code>\"*\"</code> (matches any name)</p> <pre><code># Match exact name\npattern = FileStructurePattern(directory_name=\"src\")\n\n# Match with wildcard\npattern = FileStructurePattern(directory_name=\"experiment_*\")\n\n# Match any name\npattern = FileStructurePattern(directory_name=\"*\")\n</code></pre>"},{"location":"api/pattern/#files","title":"files","text":"<p>List of required file patterns. At least one file must match each pattern.</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"*.csv\", \"config.yaml\"]\n)\n# Requires: at least one .csv file AND config.yaml\n</code></pre>"},{"location":"api/pattern/#directories","title":"directories","text":"<p>List of required subdirectory patterns. At least one directory must match each pattern.</p> <pre><code>pattern = FileStructurePattern(\n    directories=[\n        FileStructurePattern(directory_name=\"data\"),\n        FileStructurePattern(directory_name=\"models\")\n    ]\n)\n# Requires: at least one \"data\" directory AND at least one \"models\" directory\n</code></pre>"},{"location":"api/pattern/#optional_files","title":"optional_files","text":"<p>List of optional file patterns. Not required for a match.</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"config.yaml\"],\n    optional_files=[\"notes.txt\", \"debug.log\"]\n)\n# Requires config.yaml, but notes.txt and debug.log are optional\n</code></pre>"},{"location":"api/pattern/#optional_directories","title":"optional_directories","text":"<p>List of optional subdirectory patterns. Not required for a match.</p> <pre><code>pattern = FileStructurePattern(\n    directories=[\n        FileStructurePattern(directory_name=\"src\")\n    ],\n    optional_directories=[\n        FileStructurePattern(directory_name=\"docs\"),\n        FileStructurePattern(directory_name=\"tests\")\n    ]\n)\n# Requires src/, but docs/ and tests/ are optional\n</code></pre>"},{"location":"api/types/","title":"Data Types","text":"<p>Pathvein uses named tuples for data transfer objects.</p>"},{"location":"api/types/#scanresult","title":"ScanResult","text":"<p>Returned by <code>scan()</code> and <code>assess()</code> functions.</p>"},{"location":"api/types/#pathvein.lib.ScanResult","title":"pathvein.lib.ScanResult","text":"<p>               Bases: <code>NamedTuple</code></p> <p>source: Path pattern: FileStructurePattern</p> Source code in <code>src/pathvein/lib.py</code> <pre><code>class ScanResult(NamedTuple):\n    \"\"\"\n    source: Path\n    pattern: FileStructurePattern\n    \"\"\"\n\n    source: Path\n    pattern: FileStructurePattern\n</code></pre>"},{"location":"api/types/#fields","title":"Fields","text":"<ul> <li><code>source: Path</code> - The directory that matched the pattern</li> <li><code>pattern: FileStructurePattern</code> - The pattern that was matched</li> </ul>"},{"location":"api/types/#usage","title":"Usage","text":"<pre><code>from pathvein import scan, FileStructurePattern\nfrom pathlib import Path\n\npattern = FileStructurePattern(files=[\"*.csv\"])\nmatches = scan(Path(\"data\"), [pattern])\n\nfor match in matches:\n    print(f\"Directory: {match.source}\")\n    print(f\"Pattern: {match.pattern.directory_name}\")\n</code></pre>"},{"location":"api/types/#shuffleinput","title":"ShuffleInput","text":"<p>Input to the <code>shuffle()</code> function.</p>"},{"location":"api/types/#pathvein.lib.ShuffleInput","title":"pathvein.lib.ShuffleInput","text":"<p>               Bases: <code>NamedTuple</code></p> <p>source: Path destination: Path pattern: FileStructurePattern</p> Source code in <code>src/pathvein/lib.py</code> <pre><code>class ShuffleInput(NamedTuple):\n    \"\"\"\n    source: Path\n    destination: Path\n    pattern: FileStructurePattern\n    \"\"\"\n\n    source: Path\n    destination: Path\n    pattern: FileStructurePattern\n</code></pre>"},{"location":"api/types/#fields_1","title":"Fields","text":"<ul> <li><code>source: Path</code> - Source directory to copy from</li> <li><code>destination: Path</code> - Destination directory to copy to</li> <li><code>pattern: FileStructurePattern</code> - Pattern defining what to copy</li> </ul>"},{"location":"api/types/#usage_1","title":"Usage","text":"<pre><code>from pathvein import shuffle, ShuffleInput, FileStructurePattern\nfrom pathlib import Path\n\npattern = FileStructurePattern(files=[\"*.csv\"])\n\nshuffle_def = [\n    ShuffleInput(\n        source=Path(\"data/exp_001\"),\n        destination=Path(\"backup/exp_001\"),\n        pattern=pattern\n    )\n]\n\nresults = shuffle(shuffle_def)\n</code></pre>"},{"location":"api/types/#creating-from-scanresults","title":"Creating from ScanResults","text":"<pre><code>from pathvein import scan, shuffle, ShuffleInput\n\nmatches = scan(Path(\"data\"), [pattern])\n\nshuffle_def = [\n    ShuffleInput(\n        source=match.source,\n        destination=Path(\"backup\") / match.source.name,\n        pattern=match.pattern\n    )\n    for match in matches\n]\n\nresults = shuffle(shuffle_def)\n</code></pre>"},{"location":"api/types/#shuffleresult","title":"ShuffleResult","text":"<p>Returned by <code>shuffle()</code>, <code>shuffle_to()</code>, and <code>shuffle_with()</code> functions.</p>"},{"location":"api/types/#pathvein.lib.ShuffleResult","title":"pathvein.lib.ShuffleResult","text":"<p>               Bases: <code>NamedTuple</code></p> <p>source: Path destination: Path pattern: FileStructurePattern</p> Source code in <code>src/pathvein/lib.py</code> <pre><code>class ShuffleResult(NamedTuple):\n    \"\"\"\n    source: Path\n    destination: Path\n    pattern: FileStructurePattern\n    \"\"\"\n\n    source: Path\n    destination: Path\n    pattern: FileStructurePattern\n</code></pre>"},{"location":"api/types/#fields_2","title":"Fields","text":"<ul> <li><code>source: Path</code> - Source directory that was copied</li> <li><code>destination: Path</code> - Destination directory where it was copied to</li> <li><code>pattern: FileStructurePattern</code> - Pattern that was used for copying</li> </ul>"},{"location":"api/types/#usage_2","title":"Usage","text":"<pre><code>from pathvein import scan, shuffle_to\nfrom pathlib import Path\n\nmatches = scan(Path(\"data\"), [pattern])\nresults = shuffle_to(matches, Path(\"backup\"))\n\nfor result in results:\n    print(f\"Copied: {result.source} -&gt; {result.destination}\")\n</code></pre>"},{"location":"api/types/#checking-success","title":"Checking Success","text":"<pre><code>results = shuffle_to(matches, Path(\"backup\"))\n\nprint(f\"Successfully copied {len(results)} directories\")\n\nfor result in results:\n    if result.destination.exists():\n        print(f\"\u2713 {result.destination}\")\n    else:\n        print(f\"\u2717 {result.destination}\")\n</code></pre>"},{"location":"api/types/#type-annotations","title":"Type Annotations","text":"<p>All types are exported from the main package and can be used for type hints:</p> <pre><code>from pathlib import Path\nfrom typing import Set, List\nfrom pathvein import (\n    ScanResult,\n    ShuffleInput,\n    ShuffleResult,\n    FileStructurePattern\n)\n\ndef find_experiments(root: Path) -&gt; Set[ScanResult]:\n    pattern = FileStructurePattern(files=[\"experiment.yaml\"])\n    from pathvein import scan\n    return scan(root, [pattern])\n\ndef backup_experiments(matches: Set[ScanResult]) -&gt; List[ShuffleResult]:\n    from pathvein import shuffle_to\n    return shuffle_to(matches, Path(\"backup\"))\n</code></pre>"},{"location":"api/types/#working-with-named-tuples","title":"Working with Named Tuples","text":""},{"location":"api/types/#unpacking","title":"Unpacking","text":"<pre><code>for source, destination, pattern in results:\n    print(f\"{source} -&gt; {destination}\")\n</code></pre>"},{"location":"api/types/#converting-to-dict","title":"Converting to Dict","text":"<pre><code>result_dict = result._asdict()\n# {'source': Path('...'), 'destination': Path('...'), 'pattern': FileStructurePattern(...)}\n</code></pre>"},{"location":"api/types/#creating-from-dicts","title":"Creating from Dicts","text":"<pre><code>from pathvein import ShuffleInput\n\ndata = {\n    'source': Path('data/exp_001'),\n    'destination': Path('backup/exp_001'),\n    'pattern': pattern\n}\n\nshuffle_input = ShuffleInput(**data)\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#pypi-installation","title":"PyPI Installation","text":"<p>Pathvein is available on PyPI and can be installed with pip, pipx, or uv:</p>"},{"location":"getting-started/installation/#full-installation-recommended","title":"Full Installation (Recommended)","text":"<p>For the full experience including the CLI:</p> <pre><code>pip install 'pathvein[cli]'\n</code></pre> <p>Or with pipx for isolated CLI installation:</p> <pre><code>pipx install 'pathvein[cli]'\n</code></pre> <p>Or run directly with uv:</p> <pre><code>uvx --with 'pathvein[cli]' pathvein\n</code></pre>"},{"location":"getting-started/installation/#library-only","title":"Library Only","text":"<p>For programmatic use only (no CLI):</p> <pre><code>pip install pathvein\n</code></pre>"},{"location":"getting-started/installation/#with-s3-support","title":"With S3 Support","text":"<p>To work with S3 and other cloud storage:</p> <pre><code>pip install 'pathvein[s3]'\n</code></pre>"},{"location":"getting-started/installation/#all-extras","title":"All Extras","text":"<p>To install everything:</p> <pre><code>pip install 'pathvein[cli,s3]'\n</code></pre>"},{"location":"getting-started/installation/#building-from-source","title":"Building from Source","text":"<p>To build from source (requires Rust toolchain for full performance):</p> <pre><code>git clone https://github.com/alexjbuck/pathvein.git\ncd pathvein\npip install .\n</code></pre> <p>If you don't have Rust installed, pathvein will fall back to pure Python automatically.</p>"},{"location":"getting-started/installation/#installing-rust","title":"Installing Rust","text":"<p>To get the Rust-powered performance improvements, install the Rust toolchain:</p> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre> <p>Or visit rustup.rs for other installation methods.</p>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>Check that pathvein is installed correctly:</p> <pre><code>python -c \"import pathvein; print(pathvein.__version__)\"\n</code></pre> <p>Check which backend is active:</p> <pre><code>python -c \"from pathvein import get_backend_info; print(get_backend_info())\"\n</code></pre> <p>You should see either <code>rust</code> (best performance) or <code>python</code> (fallback) as the backend.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>Optional: Rust 1.70+ for building with the Rust backend</li> <li>Optional: typer for CLI functionality</li> <li>Optional: fsspec and universal-pathlib for S3 support</li> </ul>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have pathvein installed, check out the Quick Start Guide to learn the basics!</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will walk you through the basics of using pathvein.</p>"},{"location":"getting-started/quick-start/#basic-concepts","title":"Basic Concepts","text":"<p>Pathvein works with three main concepts:</p> <ol> <li>Patterns: Definitions of file structure requirements</li> <li>Scanning: Finding directories that match patterns</li> <li>Shuffling: Copying matched structures to organized destinations</li> </ol>"},{"location":"getting-started/quick-start/#your-first-pattern","title":"Your First Pattern","text":"<p>Let's create a simple pattern that matches directories containing specific files:</p> <pre><code>from pathvein import FileStructurePattern\n\n# A simple experiment directory pattern\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",  # Must start with \"experiment_\"\n    files=[\"data.csv\", \"config.yaml\"],  # Must have these files\n    optional_files=[\"notes.txt\"]  # May have this file\n)\n</code></pre>"},{"location":"getting-started/quick-start/#scanning-for-matches","title":"Scanning for Matches","text":"<p>Now let's scan a directory to find all matches:</p> <pre><code>from pathlib import Path\nfrom pathvein import scan\n\n# Scan the data directory\nmatches = scan(\n    source=Path(\"data\"),\n    patterns=[pattern]\n)\n\n# Print all matches\nfor match in matches:\n    print(f\"Found: {match.source}\")\n</code></pre>"},{"location":"getting-started/quick-start/#organizing-matches","title":"Organizing Matches","text":"<p>Once you have matches, you can copy them to an organized destination:</p> <pre><code>from pathvein import shuffle_to\n\n# Copy all matches to a single destination\nresults = shuffle_to(\n    matches=matches,\n    destination=Path(\"organized_data\"),\n    overwrite=False,  # Don't overwrite existing files\n    dryrun=False  # Actually perform the copy\n)\n\n# See what was copied\nfor result in results:\n    print(f\"Copied {result.source} to {result.destination}\")\n</code></pre>"},{"location":"getting-started/quick-start/#nested-patterns","title":"Nested Patterns","text":"<p>Patterns can be nested to match complex directory structures:</p> <pre><code>pattern = FileStructurePattern(\n    directory_name=\"project_*\",\n    files=[\"README.md\"],\n    directories=[\n        FileStructurePattern(\n            directory_name=\"src\",\n            files=[\"__init__.py\"]\n        ),\n        FileStructurePattern(\n            directory_name=\"tests\",\n            files=[\"test_*.py\"]\n        )\n    ],\n    optional_directories=[\n        FileStructurePattern(\n            directory_name=\"docs\"\n        )\n    ]\n)\n</code></pre> <p>This pattern matches directories like:</p> <pre><code>project_foo/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_main.py\n</code></pre>"},{"location":"getting-started/quick-start/#using-wildcards","title":"Using Wildcards","text":"<p>Pathvein supports glob patterns for file and directory names:</p> <pre><code>pattern = FileStructurePattern(\n    directory_name=\"*\",  # Any directory name\n    files=[\"*.csv\", \"config.*\"],  # Any CSV file and config file with any extension\n    optional_files=[\"data_[0-9][0-9].txt\"]  # Optional numbered data files\n)\n</code></pre>"},{"location":"getting-started/quick-start/#loading-patterns-from-json","title":"Loading Patterns from JSON","text":"<p>You can save and load patterns as JSON:</p> <pre><code># Save pattern\npattern_json = pattern.to_json()\nPath(\"pattern.json\").write_text(pattern_json)\n\n# Load pattern\nloaded_pattern = FileStructurePattern.load_json(Path(\"pattern.json\"))\n</code></pre>"},{"location":"getting-started/quick-start/#advanced-custom-destinations","title":"Advanced: Custom Destinations","text":"<p>Use <code>shuffle_with</code> for custom destination logic:</p> <pre><code>from pathvein import shuffle_with\n\ndef compute_destination(scan_result):\n    \"\"\"Sort experiments by year\"\"\"\n    # Extract year from directory name like \"experiment_2023_01\"\n    year = scan_result.source.name.split(\"_\")[1]\n    return Path(f\"organized/{year}/{scan_result.source.name}\")\n\nresults = shuffle_with(\n    matches=matches,\n    destination_fn=compute_destination\n)\n</code></pre>"},{"location":"getting-started/quick-start/#command-line-usage","title":"Command Line Usage","text":"<p>If you installed with <code>[cli]</code>, you can use pathvein from the command line:</p> <pre><code># Scan for matches\npathvein scan data/ --pattern pattern.json\n\n# Scan and copy\npathvein shuffle data/ organized_data/ --pattern pattern.json\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more about patterns</li> <li>Explore scanning options</li> <li>Master shuffling strategies</li> <li>Check out the full API Reference</li> </ul>"},{"location":"guide/patterns/","title":"Working with Patterns","text":"<p>File structure patterns are the core of pathvein. They define what you're looking for in your file system.</p>"},{"location":"guide/patterns/#pattern-components","title":"Pattern Components","text":"<p>A <code>FileStructurePattern</code> has five main components:</p> Component Type Description <code>directory_name</code> <code>str</code> Glob pattern for the directory name (default: <code>\"*\"</code>) <code>files</code> <code>List[str]</code> Required file patterns that must exist <code>directories</code> <code>List[FileStructurePattern]</code> Required subdirectories that must exist <code>optional_files</code> <code>List[str]</code> Optional file patterns <code>optional_directories</code> <code>List[FileStructurePattern]</code> Optional subdirectories"},{"location":"guide/patterns/#creating-patterns","title":"Creating Patterns","text":""},{"location":"guide/patterns/#basic-pattern","title":"Basic Pattern","text":"<pre><code>from pathvein import FileStructurePattern\n\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"data.csv\", \"metadata.json\"]\n)\n</code></pre>"},{"location":"guide/patterns/#using-builder-methods","title":"Using Builder Methods","text":"<p>Patterns support a fluent builder interface:</p> <pre><code>pattern = (\n    FileStructurePattern()\n    .set_directory_name(\"project_*\")\n    .add_file(\"README.md\")\n    .add_files([\"setup.py\", \"pyproject.toml\"])\n    .add_file(\"notes.txt\", is_optional=True)\n)\n</code></pre>"},{"location":"guide/patterns/#nested-patterns","title":"Nested Patterns","text":"<p>Create deep hierarchy requirements:</p> <pre><code>src_pattern = FileStructurePattern(\n    directory_name=\"src\",\n    files=[\"__init__.py\", \"main.py\"]\n)\n\ntest_pattern = FileStructurePattern(\n    directory_name=\"tests\",\n    files=[\"test_*.py\"]\n)\n\nproject_pattern = FileStructurePattern(\n    directory_name=\"my_project\",\n    files=[\"README.md\"],\n    directories=[src_pattern, test_pattern]\n)\n</code></pre>"},{"location":"guide/patterns/#glob-patterns","title":"Glob Patterns","text":"<p>Pathvein uses glob-style pattern matching for filenames and directory names.</p>"},{"location":"guide/patterns/#common-glob-patterns","title":"Common Glob Patterns","text":"Pattern Matches Example <code>*</code> Any characters <code>*.csv</code> matches <code>data.csv</code>, <code>results.csv</code> <code>?</code> Single character <code>test?.py</code> matches <code>test1.py</code>, <code>testA.py</code> <code>[abc]</code> Any character in brackets <code>data[123].txt</code> matches <code>data1.txt</code>, <code>data2.txt</code> <code>[!abc]</code> Any character NOT in brackets <code>data[!0].txt</code> matches <code>data1.txt</code> but not <code>data0.txt</code> <code>[a-z]</code> Character range <code>exp_[0-9].csv</code> matches <code>exp_0.csv</code> through <code>exp_9.csv</code>"},{"location":"guide/patterns/#examples","title":"Examples","text":"<pre><code># Match any Python file\npattern = FileStructurePattern(\n    directory_name=\"*\",\n    files=[\"*.py\"]\n)\n\n# Match numbered experiment directories\npattern = FileStructurePattern(\n    directory_name=\"experiment_[0-9][0-9]\",\n    files=[\"data_*.csv\"]\n)\n\n# Match multiple file types\npattern = FileStructurePattern(\n    directory_name=\"*\",\n    files=[\"report.*\"]  # Matches report.pdf, report.docx, etc.\n)\n</code></pre>"},{"location":"guide/patterns/#required-vs-optional","title":"Required vs Optional","text":"<p>The distinction between required and optional components is important:</p>"},{"location":"guide/patterns/#required-components","title":"Required Components","text":"<p>Must be present for a match:</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"config.yaml\"],  # Must exist\n    directories=[           # At least one must exist\n        FileStructurePattern(directory_name=\"data\")\n    ]\n)\n</code></pre>"},{"location":"guide/patterns/#optional-components","title":"Optional Components","text":"<p>May or may not be present:</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"config.yaml\"],\n    optional_files=[\"notes.txt\"],  # Nice to have, but not required\n    optional_directories=[\n        FileStructurePattern(directory_name=\"backup\")\n    ]\n)\n</code></pre>"},{"location":"guide/patterns/#pattern-validation","title":"Pattern Validation","text":"<p>Patterns validate directory structures by checking:</p> <ol> <li>Directory name matches the pattern</li> <li>All required files exist (at least one match per pattern)</li> <li>All required subdirectories exist and match their patterns</li> <li>Optional components are ignored if missing</li> </ol>"},{"location":"guide/patterns/#json-serialization","title":"JSON Serialization","text":"<p>Patterns can be saved and loaded as JSON:</p>"},{"location":"guide/patterns/#saving-patterns","title":"Saving Patterns","text":"<pre><code>pattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"data.csv\", \"config.yaml\"]\n)\n\n# Convert to JSON string\njson_str = pattern.to_json()\n\n# Save to file\nfrom pathlib import Path\nPath(\"pattern.json\").write_text(json_str)\n</code></pre>"},{"location":"guide/patterns/#loading-patterns","title":"Loading Patterns","text":"<pre><code>from pathlib import Path\nfrom pathvein import FileStructurePattern\n\n# Load from file\npattern = FileStructurePattern.load_json(Path(\"pattern.json\"))\n\n# Load from string\npattern = FileStructurePattern.from_json(json_str)\n</code></pre>"},{"location":"guide/patterns/#json-format","title":"JSON Format","text":"<p>Here's what the JSON looks like:</p> <pre><code>{\n  \"directory_name\": \"experiment_*\",\n  \"files\": [\"data.csv\", \"config.yaml\"],\n  \"directories\": [\n    {\n      \"directory_name\": \"raw\",\n      \"files\": [\"*.csv\"],\n      \"directories\": [],\n      \"optional_files\": [],\n      \"optional_directories\": []\n    }\n  ],\n  \"optional_files\": [\"notes.txt\"],\n  \"optional_directories\": []\n}\n</code></pre>"},{"location":"guide/patterns/#pattern-matching-behavior","title":"Pattern Matching Behavior","text":""},{"location":"guide/patterns/#file-pattern-matching","title":"File Pattern Matching","text":"<p>When matching file patterns, at least one file must match each required pattern:</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"*.csv\", \"*.json\"]\n)\n</code></pre> <p>This requires: - At least one <code>.csv</code> file AND - At least one <code>.json</code> file</p>"},{"location":"guide/patterns/#directory-pattern-matching","title":"Directory Pattern Matching","text":"<p>For required subdirectories, at least one directory must match each pattern:</p> <pre><code>pattern = FileStructurePattern(\n    directories=[\n        FileStructurePattern(directory_name=\"data_*\")\n    ]\n)\n</code></pre> <p>This requires at least one directory whose name matches <code>data_*</code>.</p>"},{"location":"guide/patterns/#advanced-reverse-pattern-matching","title":"Advanced: Reverse Pattern Matching","text":"<p>The <code>parents_of()</code> method finds candidate root directories for a file:</p> <pre><code>from pathlib import Path\n\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"data.csv\", \"results.csv\"]\n)\n\n# Find possible root directories for this file\nfile = Path(\"data/experiment_001/results.csv\")\ncandidates = pattern.parents_of(file)\n\n# candidates might include: {Path(\"data/experiment_001\")}\n</code></pre> <p>This is useful with the <code>assess()</code> function to determine which pattern a file belongs to.</p>"},{"location":"guide/patterns/#best-practices","title":"Best Practices","text":""},{"location":"guide/patterns/#be-specific","title":"Be Specific","text":"<p>Prefer specific patterns over wildcards when possible:</p> <pre><code># Good - specific\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"config.yaml\", \"results.csv\"]\n)\n\n# Less good - too broad\npattern = FileStructurePattern(\n    directory_name=\"*\",\n    files=[\"*\"]\n)\n</code></pre>"},{"location":"guide/patterns/#use-optional-wisely","title":"Use Optional Wisely","text":"<p>Only mark components as optional if they're truly optional:</p> <pre><code>pattern = FileStructurePattern(\n    files=[\"config.yaml\"],  # Always required\n    optional_files=[\"debug.log\"]  # Only in debug runs\n)\n</code></pre>"},{"location":"guide/patterns/#document-your-patterns","title":"Document Your Patterns","text":"<p>Add comments or save patterns with descriptive filenames:</p> <pre><code># experiments/pattern.json\nexperimental_run_pattern = FileStructurePattern(\n    directory_name=\"run_[0-9][0-9][0-9]\",\n    files=[\"config.yaml\", \"results.csv\"],\n    optional_files=[\"error.log\"]\n)\n</code></pre>"},{"location":"guide/patterns/#examples_1","title":"Examples","text":""},{"location":"guide/patterns/#python-project-pattern","title":"Python Project Pattern","text":"<pre><code>python_project = FileStructurePattern(\n    directory_name=\"*\",\n    files=[\"pyproject.toml\"],\n    directories=[\n        FileStructurePattern(\n            directory_name=\"src\",\n            files=[\"__init__.py\"]\n        )\n    ],\n    optional_files=[\"README.md\", \"LICENSE\"],\n    optional_directories=[\n        FileStructurePattern(directory_name=\"tests\"),\n        FileStructurePattern(directory_name=\"docs\")\n    ]\n)\n</code></pre>"},{"location":"guide/patterns/#data-science-experiment-pattern","title":"Data Science Experiment Pattern","text":"<pre><code>experiment_pattern = FileStructurePattern(\n    directory_name=\"exp_*\",\n    files=[\"config.json\", \"results.csv\"],\n    directories=[\n        FileStructurePattern(\n            directory_name=\"data\",\n            files=[\"*.parquet\"]\n        ),\n        FileStructurePattern(\n            directory_name=\"models\",\n            files=[\"model_*.pkl\"]\n        )\n    ],\n    optional_files=[\"notes.md\", \"plot_*.png\"],\n    optional_directories=[\n        FileStructurePattern(directory_name=\"checkpoints\")\n    ]\n)\n</code></pre>"},{"location":"guide/scanning/","title":"Scanning Directories","text":"<p>The <code>scan()</code> function recursively searches directories to find structures that match your patterns.</p>"},{"location":"guide/scanning/#basic-scanning","title":"Basic Scanning","text":"<pre><code>from pathlib import Path\nfrom pathvein import scan, FileStructurePattern\n\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"data.csv\"]\n)\n\nmatches = scan(\n    source=Path(\"data\"),\n    patterns=[pattern]\n)\n\nfor match in matches:\n    print(f\"Found: {match.source}\")\n</code></pre>"},{"location":"guide/scanning/#return-value","title":"Return Value","text":"<p><code>scan()</code> returns a <code>Set[ScanResult]</code>, where each <code>ScanResult</code> is a named tuple with:</p> <ul> <li><code>source: Path</code> - The directory that matched</li> <li><code>pattern: FileStructurePattern</code> - Which pattern it matched</li> </ul> <pre><code>from pathvein import ScanResult\n\nfor match in matches:\n    print(f\"Directory: {match.source}\")\n    print(f\"Pattern: {match.pattern.directory_name}\")\n</code></pre>"},{"location":"guide/scanning/#multiple-patterns","title":"Multiple Patterns","text":"<p>You can search for multiple patterns simultaneously:</p> <pre><code>python_project = FileStructurePattern(\n    files=[\"pyproject.toml\", \"setup.py\"]\n)\n\nrust_project = FileStructurePattern(\n    files=[\"Cargo.toml\"]\n)\n\nmatches = scan(\n    source=Path(\"projects\"),\n    patterns=[python_project, rust_project]\n)\n\n# Each match tells you which pattern it matched\nfor match in matches:\n    if match.pattern == python_project:\n        print(f\"Python project: {match.source}\")\n    else:\n        print(f\"Rust project: {match.source}\")\n</code></pre>"},{"location":"guide/scanning/#performance","title":"Performance","text":""},{"location":"guide/scanning/#rust-backend","title":"Rust Backend","text":"<p>By default, <code>scan()</code> uses the Rust backend for local filesystems, providing 5-10x faster directory traversal:</p> <pre><code># Check which backend is active\nfrom pathvein import get_backend_info\nprint(get_backend_info())  # 'rust' or 'python'\n</code></pre>"},{"location":"guide/scanning/#cloud-storage","title":"Cloud Storage","text":"<p>For cloud storage paths (S3, GCS, etc.), pathvein automatically uses the Python backend with fsspec:</p> <pre><code>from upath import UPath\n\n# Automatically uses Python backend for S3\nmatches = scan(\n    source=UPath(\"s3://my-bucket/data/\"),\n    patterns=[pattern]\n)\n</code></pre> <p>Install S3 support with:</p> <pre><code>pip install 'pathvein[s3]'\n</code></pre>"},{"location":"guide/scanning/#caching","title":"Caching","text":"<p>Pathvein caches directory listings internally, which dramatically improves performance for network filesystems or repeated scans:</p> <ul> <li>Local filesystems: ~2x speedup from caching</li> <li>Network filesystems: ~100x+ speedup from caching</li> </ul> <p>The cache is thread-safe and automatically managed.</p>"},{"location":"guide/scanning/#filtering-results","title":"Filtering Results","text":"<p>Since <code>scan()</code> returns a set, you can use standard Python set operations:</p> <pre><code># Filter by directory name\nmatched_2023 = {m for m in matches if \"2023\" in m.source.name}\n\n# Filter by pattern\npython_matches = {m for m in matches if m.pattern == python_project}\n\n# Get just the paths\npaths = {m.source for m in matches}\n</code></pre>"},{"location":"guide/scanning/#working-with-results","title":"Working with Results","text":""},{"location":"guide/scanning/#counting-matches","title":"Counting Matches","text":"<pre><code>print(f\"Found {len(matches)} matching directories\")\n</code></pre>"},{"location":"guide/scanning/#grouping-by-pattern","title":"Grouping by Pattern","text":"<pre><code>from collections import defaultdict\n\nby_pattern = defaultdict(list)\nfor match in matches:\n    by_pattern[match.pattern].append(match.source)\n\nfor pattern, paths in by_pattern.items():\n    print(f\"Pattern {pattern.directory_name}: {len(paths)} matches\")\n</code></pre>"},{"location":"guide/scanning/#sorting-results","title":"Sorting Results","text":"<pre><code># Sort by path name\nsorted_matches = sorted(matches, key=lambda m: m.source.name)\n\n# Sort by modification time\nsorted_matches = sorted(matches, key=lambda m: m.source.stat().st_mtime)\n</code></pre>"},{"location":"guide/scanning/#advanced-the-assess-function","title":"Advanced: The assess() Function","text":"<p>While <code>scan()</code> searches directories top-down, <code>assess()</code> works backwards from a file to find which patterns it belongs to:</p> <pre><code>from pathlib import Path\nfrom pathvein import assess, FileStructurePattern\n\npatterns = [\n    FileStructurePattern(\n        directory_name=\"experiment_*\",\n        files=[\"data.csv\", \"results.csv\"]\n    ),\n    FileStructurePattern(\n        directory_name=\"backup_*\",\n        files=[\"*.csv\"]\n    )\n]\n\n# Given a file, find which pattern it belongs to\nfile = Path(\"data/experiment_001/results.csv\")\n\nfor result in assess(file, patterns):\n    print(f\"File belongs to pattern: {result.pattern.directory_name}\")\n    print(f\"Pattern root: {result.source}\")\n</code></pre>"},{"location":"guide/scanning/#use-cases-for-assess","title":"Use Cases for assess()","text":"<p>Validation: Check if a file is in the right place</p> <pre><code>file = Path(\"data/experiment_001/results.csv\")\nresults = list(assess(file, [experiment_pattern]))\n\nif results:\n    print(f\"\u2713 File is in valid experiment directory: {results[0].source}\")\nelse:\n    print(\"\u2717 File is not in a valid experiment directory\")\n</code></pre> <p>Discovery: Find the root directory of a pattern</p> <pre><code># You have a file deep in the structure\ndeep_file = Path(\"projects/myapp/src/lib/utils/helpers.py\")\n\n# Find the project root\nfor result in assess(deep_file, [python_project_pattern]):\n    project_root = result.source\n    print(f\"Project root: {project_root}\")\n</code></pre> <p>Reverse Engineering: Determine file organization</p> <pre><code>unknown_file = Path(\"data/some_directory/output.csv\")\n\nfor result in assess(unknown_file, known_patterns):\n    print(f\"This file follows the '{result.pattern.directory_name}' pattern\")\n</code></pre>"},{"location":"guide/scanning/#examples","title":"Examples","text":""},{"location":"guide/scanning/#find-all-python-projects","title":"Find All Python Projects","text":"<pre><code>from pathlib import Path\nfrom pathvein import scan, FileStructurePattern\n\npython_pattern = FileStructurePattern(\n    files=[\"pyproject.toml\"],\n    directories=[\n        FileStructurePattern(\n            directory_name=\"src\",\n            files=[\"*.py\"]\n        )\n    ]\n)\n\nmatches = scan(\n    source=Path(\"~/projects\").expanduser(),\n    patterns=[python_pattern]\n)\n\nprint(f\"Found {len(matches)} Python projects:\")\nfor match in matches:\n    print(f\"  {match.source}\")\n</code></pre>"},{"location":"guide/scanning/#find-incomplete-experiments","title":"Find Incomplete Experiments","text":"<pre><code>complete_pattern = FileStructurePattern(\n    directory_name=\"exp_*\",\n    files=[\"config.json\", \"results.csv\", \"summary.txt\"]\n)\n\nincomplete_pattern = FileStructurePattern(\n    directory_name=\"exp_*\",\n    files=[\"config.json\"],\n    optional_files=[\"results.csv\", \"summary.txt\"]\n)\n\ncomplete = scan(Path(\"experiments\"), [complete_pattern])\nall_exps = scan(Path(\"experiments\"), [incomplete_pattern])\n\nincomplete = all_exps - complete\n\nprint(f\"Complete experiments: {len(complete)}\")\nprint(f\"Incomplete experiments: {len(incomplete)}\")\nfor exp in incomplete:\n    print(f\"  {exp.source.name}\")\n</code></pre>"},{"location":"guide/scanning/#find-projects-by-technology","title":"Find Projects by Technology","text":"<pre><code>patterns = {\n    \"Python\": FileStructurePattern(files=[\"pyproject.toml\"]),\n    \"Rust\": FileStructurePattern(files=[\"Cargo.toml\"]),\n    \"Node.js\": FileStructurePattern(files=[\"package.json\"]),\n    \"Go\": FileStructurePattern(files=[\"go.mod\"])\n}\n\nfor tech, pattern in patterns.items():\n    matches = scan(Path(\"projects\"), [pattern])\n    print(f\"{tech} projects: {len(matches)}\")\n</code></pre>"},{"location":"guide/scanning/#best-practices","title":"Best Practices","text":""},{"location":"guide/scanning/#start-specific-then-broaden","title":"Start Specific, Then Broaden","text":"<p>Start with specific patterns and loosen them if needed:</p> <pre><code># Start specific\npattern = FileStructurePattern(\n    directory_name=\"experiment_[0-9][0-9][0-9]\",\n    files=[\"config.yaml\", \"results.csv\"]\n)\n\n# If too restrictive, make optional\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"config.yaml\"],\n    optional_files=[\"results.csv\"]  # May not exist yet\n)\n</code></pre>"},{"location":"guide/scanning/#handle-empty-results","title":"Handle Empty Results","text":"<p>Always check if you got matches:</p> <pre><code>matches = scan(source, patterns)\n\nif not matches:\n    print(\"No matches found. Check your patterns and source directory.\")\nelse:\n    print(f\"Found {len(matches)} matches\")\n</code></pre>"},{"location":"guide/scanning/#use-logging-for-debugging","title":"Use Logging for Debugging","text":"<p>Enable logging to see what pathvein is doing:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\nmatches = scan(source, patterns)\n</code></pre>"},{"location":"guide/shuffling/","title":"Shuffling (Copying) Matched Structures","text":"<p>After scanning for matches, you often want to copy them to organized destinations. Pathvein provides three \"shuffle\" functions for different use cases.</p>"},{"location":"guide/shuffling/#overview","title":"Overview","text":"Function Use Case Destination <code>shuffle_to()</code> Copy all matches to one location Single directory, flat structure <code>shuffle_with()</code> Custom destination logic Computed per-match <code>shuffle()</code> Full control Explicitly specified"},{"location":"guide/shuffling/#shuffle_to-simple-consolidation","title":"shuffle_to(): Simple Consolidation","text":"<p>Copy all matches into a single destination directory:</p> <pre><code>from pathlib import Path\nfrom pathvein import scan, shuffle_to, FileStructurePattern\n\npattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"results.csv\"]\n)\n\nmatches = scan(Path(\"data\"), [pattern])\n\nresults = shuffle_to(\n    matches=matches,\n    destination=Path(\"organized\"),\n    overwrite=False,\n    dryrun=False\n)\n</code></pre>"},{"location":"guide/shuffling/#resulting-structure","title":"Resulting Structure","text":"<pre><code>organized/\n\u251c\u2500\u2500 experiment_001/\n\u2502   \u2514\u2500\u2500 results.csv\n\u251c\u2500\u2500 experiment_002/\n\u2502   \u2514\u2500\u2500 results.csv\n\u2514\u2500\u2500 experiment_003/\n    \u2514\u2500\u2500 results.csv\n</code></pre> <p>Each matched directory becomes a subdirectory of the destination with its original name preserved.</p>"},{"location":"guide/shuffling/#shuffle_with-custom-logic","title":"shuffle_with(): Custom Logic","text":"<p>Use a function to compute destinations dynamically:</p> <pre><code>from pathvein import shuffle_with\n\ndef organize_by_year(scan_result):\n    \"\"\"Sort experiments by year from the directory name\"\"\"\n    # Extract year from \"experiment_2023_01\"\n    parts = scan_result.source.name.split(\"_\")\n    year = parts[1] if len(parts) &gt; 1 else \"unknown\"\n    return Path(f\"organized/{year}/{scan_result.source.name}\")\n\nresults = shuffle_with(\n    matches=matches,\n    destination_fn=organize_by_year,\n    overwrite=False,\n    dryrun=False\n)\n</code></pre>"},{"location":"guide/shuffling/#resulting-structure_1","title":"Resulting Structure","text":"<pre><code>organized/\n\u251c\u2500\u2500 2023/\n\u2502   \u251c\u2500\u2500 experiment_2023_01/\n\u2502   \u2514\u2500\u2500 experiment_2023_02/\n\u251c\u2500\u2500 2024/\n\u2502   \u251c\u2500\u2500 experiment_2024_01/\n\u2502   \u2514\u2500\u2500 experiment_2024_02/\n\u2514\u2500\u2500 unknown/\n    \u2514\u2500\u2500 experiment_old/\n</code></pre>"},{"location":"guide/shuffling/#shuffle-maximum-control","title":"shuffle(): Maximum Control","text":"<p>Explicitly specify source and destination for each copy:</p> <pre><code>from pathvein import shuffle, ShuffleInput\n\n# Build shuffle inputs manually\nshuffle_def = [\n    ShuffleInput(\n        source=Path(\"data/exp_001\"),\n        destination=Path(\"results/group_a/exp_001\"),\n        pattern=pattern\n    ),\n    ShuffleInput(\n        source=Path(\"data/exp_002\"),\n        destination=Path(\"results/group_b/exp_002\"),\n        pattern=pattern\n    )\n]\n\nresults = shuffle(\n    shuffle_def=shuffle_def,\n    overwrite=False,\n    dryrun=False\n)\n</code></pre> <p>Or convert scan results:</p> <pre><code>shuffle_def = [\n    ShuffleInput(\n        source=match.source,\n        destination=compute_dest(match),\n        pattern=match.pattern\n    )\n    for match in matches\n]\n\nresults = shuffle(shuffle_def, overwrite=False, dryrun=False)\n</code></pre>"},{"location":"guide/shuffling/#common-options","title":"Common Options","text":"<p>All shuffle functions accept these options:</p>"},{"location":"guide/shuffling/#overwrite-bool-false","title":"overwrite: bool = False","text":"<p>Whether to overwrite existing files at the destination:</p> <pre><code>results = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    overwrite=True  # Overwrite existing files\n)\n</code></pre> <p>Default: <code>False</code> - Raises <code>FileExistsError</code> if destination exists</p>"},{"location":"guide/shuffling/#dryrun-bool-false","title":"dryrun: bool = False","text":"<p>Preview what would be copied without actually copying:</p> <pre><code>results = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    dryrun=True  # Don't actually copy\n)\n\nprint(f\"Would copy {len(results)} directories\")\nfor result in results:\n    print(f\"  {result.source} -&gt; {result.destination}\")\n</code></pre>"},{"location":"guide/shuffling/#use_threading-bool-false","title":"use_threading: bool = False","text":"<p>Enable parallel file copying for better performance:</p> <pre><code>results = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    use_threading=True,  # Copy files in parallel\n    max_workers=4\n)\n</code></pre> <p>Best for: Large numbers of small-to-medium files</p> <p>Not recommended for: Very large files (network bandwidth becomes bottleneck)</p>"},{"location":"guide/shuffling/#max_workers-int-4","title":"max_workers: int = 4","text":"<p>Number of worker threads when <code>use_threading=True</code>:</p> <pre><code>results = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    use_threading=True,\n    max_workers=8  # Use 8 threads\n)\n</code></pre>"},{"location":"guide/shuffling/#return-value","title":"Return Value","text":"<p>All shuffle functions return <code>List[ShuffleResult]</code>, where each <code>ShuffleResult</code> is a named tuple:</p> <pre><code>from pathvein import ShuffleResult\n\nfor result in results:\n    print(f\"Source: {result.source}\")\n    print(f\"Destination: {result.destination}\")\n    print(f\"Pattern: {result.pattern}\")\n</code></pre>"},{"location":"guide/shuffling/#pattern-based-copying","title":"Pattern-Based Copying","text":"<p>Shuffling only copies files and directories that match the pattern:</p> <pre><code>pattern = FileStructurePattern(\n    directory_name=\"experiment_*\",\n    files=[\"*.csv\"],\n    optional_files=[\"*.txt\"],\n    directories=[\n        FileStructurePattern(\n            directory_name=\"data\",\n            files=[\"*.parquet\"]\n        )\n    ]\n)\n\n# Only copies:\n# - .csv files (required)\n# - .txt files if present (optional)\n# - data/ subdirectory with .parquet files\nresults = shuffle_to(matches, Path(\"backup\"))\n</code></pre> <p>Files not matching the pattern are not copied.</p>"},{"location":"guide/shuffling/#examples","title":"Examples","text":""},{"location":"guide/shuffling/#organize-by-date","title":"Organize by Date","text":"<pre><code>from datetime import datetime\n\ndef organize_by_date(scan_result):\n    \"\"\"Organize by modification date\"\"\"\n    mtime = scan_result.source.stat().st_mtime\n    date = datetime.fromtimestamp(mtime)\n    year_month = date.strftime(\"%Y-%m\")\n    return Path(f\"archive/{year_month}/{scan_result.source.name}\")\n\nresults = shuffle_with(matches, organize_by_date)\n</code></pre> <p>Result: <pre><code>archive/\n\u251c\u2500\u2500 2024-01/\n\u2502   \u251c\u2500\u2500 experiment_001/\n\u2502   \u2514\u2500\u2500 experiment_002/\n\u2514\u2500\u2500 2024-02/\n    \u2514\u2500\u2500 experiment_003/\n</code></pre></p>"},{"location":"guide/shuffling/#organize-by-size","title":"Organize by Size","text":"<pre><code>def organize_by_size(scan_result):\n    \"\"\"Organize by directory size\"\"\"\n    size = sum(\n        f.stat().st_size\n        for f in scan_result.source.rglob(\"*\")\n        if f.is_file()\n    )\n\n    if size &gt; 1_000_000_000:  # &gt; 1GB\n        bucket = \"large\"\n    elif size &gt; 100_000_000:  # &gt; 100MB\n        bucket = \"medium\"\n    else:\n        bucket = \"small\"\n\n    return Path(f\"organized/{bucket}/{scan_result.source.name}\")\n\nresults = shuffle_with(matches, organize_by_size)\n</code></pre>"},{"location":"guide/shuffling/#flatten-structure","title":"Flatten Structure","text":"<pre><code>def flatten(scan_result):\n    \"\"\"Remove directory hierarchy, just use directory name\"\"\"\n    return Path(f\"flat/{scan_result.source.name}\")\n\nresults = shuffle_with(matches, flatten)\n</code></pre> <p>Before: <pre><code>data/\n\u251c\u2500\u2500 2023/\n\u2502   \u2514\u2500\u2500 experiment_001/\n\u2514\u2500\u2500 2024/\n    \u2514\u2500\u2500 experiment_002/\n</code></pre></p> <p>After: <pre><code>flat/\n\u251c\u2500\u2500 experiment_001/\n\u2514\u2500\u2500 experiment_002/\n</code></pre></p>"},{"location":"guide/shuffling/#selective-copying","title":"Selective Copying","text":"<pre><code>def selective_copy(scan_result):\n    \"\"\"Only copy experiments that succeeded\"\"\"\n    success_file = scan_result.source / \"success.txt\"\n    if success_file.exists():\n        return Path(f\"successful/{scan_result.source.name}\")\n    else:\n        return Path(f\"failed/{scan_result.source.name}\")\n\nresults = shuffle_with(matches, selective_copy)\n</code></pre>"},{"location":"guide/shuffling/#incremental-backup","title":"Incremental Backup","text":"<pre><code>from datetime import datetime\n\nbackup_dir = Path(f\"backups/{datetime.now().strftime('%Y%m%d')}\")\n\nresults = shuffle_to(\n    matches=matches,\n    destination=backup_dir,\n    overwrite=False  # Skip if already backed up\n)\n\nprint(f\"Backed up {len(results)} directories to {backup_dir}\")\n</code></pre>"},{"location":"guide/shuffling/#error-handling","title":"Error Handling","text":""},{"location":"guide/shuffling/#file-exists-error","title":"File Exists Error","text":"<pre><code>try:\n    results = shuffle_to(\n        matches=matches,\n        destination=Path(\"backup\"),\n        overwrite=False\n    )\nexcept FileExistsError as e:\n    print(f\"Destination already exists: {e}\")\n    # Either delete it or use overwrite=True\n</code></pre>"},{"location":"guide/shuffling/#check-before-copying","title":"Check Before Copying","text":"<pre><code># Preview with dryrun\npreview = shuffle_to(matches, dest, dryrun=True)\n\n# Check for conflicts\nconflicts = [\n    r for r in preview\n    if r.destination.exists()\n]\n\nif conflicts:\n    print(f\"Found {len(conflicts)} conflicts:\")\n    for r in conflicts:\n        print(f\"  {r.destination}\")\n\n    if input(\"Overwrite? (y/n): \").lower() == \"y\":\n        shuffle_to(matches, dest, overwrite=True)\nelse:\n    shuffle_to(matches, dest, overwrite=False)\n</code></pre>"},{"location":"guide/shuffling/#performance-tips","title":"Performance Tips","text":""},{"location":"guide/shuffling/#use-threading-for-many-small-files","title":"Use Threading for Many Small Files","text":"<pre><code>results = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    use_threading=True,\n    max_workers=8\n)\n</code></pre>"},{"location":"guide/shuffling/#avoid-threading-for-large-files","title":"Avoid Threading for Large Files","text":"<p>For very large files, threading doesn't help much:</p> <pre><code># Single-threaded for large files\nresults = shuffle_to(\n    matches=matches,\n    destination=Path(\"backup\"),\n    use_threading=False\n)\n</code></pre>"},{"location":"guide/shuffling/#cloud-storage","title":"Cloud Storage","text":"<p>For S3 or other cloud storage, install the s3 extra:</p> <pre><code>pip install 'pathvein[s3]'\n</code></pre> <p>Then use UPath:</p> <pre><code>from upath import UPath\n\nresults = shuffle_to(\n    matches=matches,\n    destination=UPath(\"s3://my-bucket/backups/\")\n)\n</code></pre>"},{"location":"guide/shuffling/#best-practices","title":"Best Practices","text":""},{"location":"guide/shuffling/#always-use-dryrun-first","title":"Always Use dryrun First","text":"<pre><code># 1. Preview\npreview = shuffle_to(matches, dest, dryrun=True)\nprint(f\"Would copy {len(preview)} directories\")\n\n# 2. Review\nfor r in preview:\n    print(f\"  {r.source.name} -&gt; {r.destination}\")\n\n# 3. Execute\nif input(\"Proceed? (y/n): \").lower() == \"y\":\n    shuffle_to(matches, dest, dryrun=False)\n</code></pre>"},{"location":"guide/shuffling/#check-disk-space","title":"Check Disk Space","text":"<pre><code>import shutil\n\n# Estimate size\ntotal_size = sum(\n    sum(f.stat().st_size for f in m.source.rglob(\"*\") if f.is_file())\n    for m in matches\n)\n\n# Check available space\nstat = shutil.disk_usage(dest)\nif stat.free &lt; total_size * 1.1:  # 10% buffer\n    print(\"Insufficient disk space!\")\nelse:\n    shuffle_to(matches, dest)\n</code></pre>"},{"location":"guide/shuffling/#log-results","title":"Log Results","text":"<pre><code>import logging\nfrom datetime import datetime\n\nlogging.basicConfig(\n    filename=f'shuffle_{datetime.now():%Y%m%d_%H%M%S}.log',\n    level=logging.INFO\n)\n\nresults = shuffle_to(matches, dest)\n\nlogging.info(f\"Copied {len(results)} directories\")\nfor r in results:\n    logging.info(f\"  {r.source} -&gt; {r.destination}\")\n</code></pre>"}]}